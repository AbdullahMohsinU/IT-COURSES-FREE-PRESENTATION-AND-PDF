<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>Database Systems: Design, Implementation, and Management, Tenth Edition</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="stylesheet.css" type="text/css" rel="stylesheet"/>
<link href="page_styles.css" type="text/css" rel="stylesheet"/>
</head>
  <body class="calibre">
<hr class="calibre10"/><p class="calibre22"><span class="calibre35"><a id="filepos2172221"></a>13 <span><span class="calibre68">B<span><span class="calibre5">USINESS</span></span> I<span><span class="calibre5">NTELLIGENCE AND</span></span> D<span><span class="calibre5">ATA</span></span> W<span><span class="calibre5">AREHOUSES</span></span></span></span></span></p>
<hr class="calibre10"/><p class="calibre9">In this chapter, you will learn:</p>
<p class="calibre45">     <img alt="img" src="images/00016.jpg" class="calibre7"/>   How business intelligence provides a comprehensive business decision support framework</p><div class="calibre3"> </div>
<p class="calibre45"><span class="calibre5">     <img alt="img" src="images/00016.jpg" class="calibre7"/>   About business intelligence architecture, its evolution, and reporting styles</span></p><div class="calibre3"> </div>
<p class="calibre45"><span class="calibre5">     <img alt="img" src="images/00016.jpg" class="calibre7"/>   About the relationship and differences between operational data and decision support data</span></p><div class="calibre3"> </div>
<p class="calibre45"><span class="calibre5">     <img alt="img" src="images/00016.jpg" class="calibre7"/>   What a data warehouse is and how to prepare data for one</span></p><div class="calibre3"> </div>
<p class="calibre45"><span class="calibre5">     <img alt="img" src="images/00016.jpg" class="calibre7"/>   What star schemas are and how they are constructed</span></p><div class="calibre3"> </div>
<p class="calibre45"><span class="calibre5">     <img alt="img" src="images/00016.jpg" class="calibre7"/>   About data analytics, data mining, and predictive analytics</span></p><div class="calibre3"> </div>
<p class="calibre45"><span class="calibre5">     <img alt="img" src="images/00016.jpg" class="calibre7"/>   About online analytical processing (OLAP)</span></p><div class="calibre3"> </div>
<p class="calibre45"><span class="calibre5">     <img alt="img" src="images/00016.jpg" class="calibre7"/>   How SQL extensions are used to support OLAP-type data manipulations</span></p>
<p class="calibre33"> </p>
<hr class="calibre10"/><p class="calibre22"><span class="calibre26"><span><span class="calibre27">P</span></span>review</span></p>
<hr class="calibre10"/><p class="calibre9">Ultimately, the reason for collecting, storing, and managing data is to generate information that becomes the basis for rational decision making. Decision support systems (DSSs) were originally developed to facilitate the decision-making process. However, as the complexity and range of information requirements increased, so did the difficulty of extracting all the necessary information from the data structures typically found in an operational database. Therefore, a new data storage facility, called a data warehouse, was developed. The data warehouse extracts or obtains its data from operational databases as well as from external sources, providing a more comprehensive data pool.</p>
<p class="calibre9">In parallel with data warehouses, new ways to analyze and present decision support data were developed. Online analytical processing (OLAP) provides advanced data analysis and visualization tools, including multidimensional data analysis. Data mining employs advanced statistical tools to analyze the wealth of data now available through data warehouses and other sources and to identify possible relationships and anomalies. Predictive analytics uses advanced statistical and modeling techniques to predict future business outcomes with great accuracy.</p>
<p class="calibre9">Business intelligence (BI) is the collection of best practices and software tools developed to support business decision making in this age of globalization, emerging markets, rapid change, and increasing regulation. This chapter explores the main concepts and components of business intelligence and decision support systems that gather, generate, and present information for business decision makers, focusing especially on the use of data warehouses.</p>
<p class="calibre33"> </p>
<hr class="calibre10"/><p class="calibre22"><span class="calibre35"><a id="filepos2176405"></a>13.1 T<span><span class="calibre68">HE</span></span> N<span><span class="calibre68">EED FOR</span></span> D<span><span class="calibre68">ATA</span></span> A<span><span class="calibre68">NALYSIS</span></span></span></p>
<hr class="calibre10"/><p class="calibre9">Organizations tend to grow and prosper as they gain a better understanding of their environment. Most managers need to track daily transactions to evaluate how the business is performing. By tapping into the operational database, management can develop an understanding of how the company is performing and evaluate whether the current strategies meet organizational goals. In addition, analyzing the company data can provide insightful information about short-term tactical evaluations and strategic questions, such as: Are our sales promotions working? What market percentage are we controlling? Are we attracting new customers? Tactical and strategic decisions are also shaped by constant pressure from external and internal forces, including globalization, the cultural and legal environment, and technology.</p>
<p class="calibre9">Organizations are always looking for a competitive advantage through product development, market positioning, sales promotions, and customer service. Thanks to the Internet, customers are more informed than ever about the products they want and the prices they are willing to pay. Technology advances allow customers to place orders using their smart phones while they commute to work in the morning. Decision makers can no longer wait a couple of days for a report to be generated; they are compelled to make quick decisions if they want to remain competitive. Every day, TV ads offer low-price warranties, instant price matching, and so on. How can companies survive on lower margins and still make a profit? The key is in having the right data at the right time to support the decision-making process.</p>
<p class="calibre9">This process takes place at all levels of an organization. For example, transaction-processing systems, based on operational databases, are tailored to serve the information needs of people who deal with short-term inventory, accounts payable, and purchasing. Middle-level managers, general managers, vice presidents, and presidents focus on strategic and tactical decision making. Those managers require summarized information designed to help them make decisions in a complex business environment.</p>
<p class="calibre9">Companies and software vendors addressed these multilevel decision support needs by creating autonomous applications for particular groups of users, such as those in finance, customer management, human resources, and product support. Applications were also tailored to different industries such as education, retail, health care, and finance. This approach worked well for some time, but changes in the business world, such as globalization, expanding markets, mergers and acquisitions, increased regulation, and new technologies, called for new ways of integrating and managing decision support across levels, sectors, and geographic locations. This more comprehensive and integrated decision support framework within organizations became known as business intelligence.</p>
<p class="calibre33"> </p>
<hr class="calibre10"/><p class="calibre22"><span class="calibre35"><a id="filepos2179920"></a>13.2 B<span><span class="calibre68">USINESS</span></span> I<span><span class="calibre68">NTELLIGENCE</span></span></span></p>
<hr class="calibre10"/><p class="calibre9"><a id="filepos2180106"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2737855">Business intelligence (BI)</a><sup class="calibre56"><a href="#filepos2373333">1</a></sup> is a term that describes a comprehensive, cohesive, and integrated set of tools and processes used to capture, collect, integrate, store, and analyze data with the purpose of generating and presenting information to support business decision making. This intelligence is based on learning and understanding the facts about the business environment. BI is a framework that allows a business to transform data into information, information into knowledge, and knowledge into wisdom. BI has the potential to positively affect a company’s culture by creating continuous business performance improvement through active decision support at all levels in an organization. This business insight empowers users to make sound decisions based on the accumulated knowledge of the business.</p>
<p class="calibre9">BI’s initial adopters were high-volume industries such as financial services, insurance, and healthcare companies. As BI technology evolved, its usage spread to other industries such as telecommunications, retail/merchandising, manufacturing, media, government, and even education. <a href="#filepos2181659">Table 13.1</a> lists some companies that have implemented BI tools and shows how the tools benefited the companies. You will learn about these tools later in the chapter.</p>
<p class="calibre48"> </p>
<hr class="calibre10"/><p class="calibre63"><span class="calibre8"><span class="calibre14"><a id="filepos2181659"></a><span class="calibre14">TABLE 13.1 Solving Business Problems and Adding Value with BI Tools</span></span></span></p><div class="calibre64"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00491.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<hr class="calibre10"/><p class="calibre9">Implementing BI in an organization involves capturing not only internal and external business data, but also the metadata, or knowledge about the data. In practice, BI is a complex proposition that requires a deep understanding and alignment of the business processes, business data, and information needs of users at all levels in an organization. (See Appendix O, Data Warehouse Implementation Factors.)</p>
<p class="calibre9">BI is not a product by itself, but a framework of concepts, practices, tools, and technologies that help a business better understand its core capabilities, provide snapshots of the company situation, and identify key opportunities to create competitive advantage. In general, BI provides a framework for:</p>
<p class="calibre81"><span class="calibre5">  1.  Collecting and storing operational data</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">  2.  Aggregating the operational data into decision support data</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">  3.  Analyzing decision support data to generate information</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">  4.  Presenting such information to the end user to support business decisions</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">  5.  Making business decisions, which in turn generate more data that are collected, stored, and so on (restarting the process)</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">  6.  Monitoring results to evaluate outcomes of the business decisions, which again provides more data to be collected, stored, and so on</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">  7.  Predicting future behaviors and outcomes with a high degree of accuracy</span></p>
<p class="calibre9">The seven preceding points represent a systemwide view of the flow of data, processes, and outcomes within the BI framework. In practice, the first point, collecting and storing operational data, does not fall into the realm of a BI system per se; rather, it is the function of an operational system. However, the BI system will use the operational data as input material from which information will be derived. The rest of the processes and outcomes explained in the preceding points are oriented toward generating knowledge, and they are the focus of the BI system.</p>
<p class="calibre9">In the following section, you will learn about the basic BI architecture.</p>
<p class="calibre69"><span class="calibre8"><a id="filepos2184804"></a><span class="calibre14">13.2.1 B<span><span class="calibre5">USINESS</span></span> I<span><span class="calibre5">NTELLIGENCE</span></span> A<span><span class="calibre5">RCHITECTURE</span></span></span></span></p>
<hr class="calibre10"/><p class="calibre9">BI covers a range of technologies and applications to manage the entire data life cycle from acquisition to storage, transformation, integration, presentation, analysis, monitoring, and archiving. BI functionality ranges from simple data gathering and transformation to very complex data analysis and presentation. BI architecture ranges from highly integrated single-vendor systems to loosely integrated, multivendor environments. However, some common functions are expected in most BI implementations.</p>
<p class="calibre9">Like any critical business IT infrastructure, the BI architecture is composed of data, people, processes, technology, and the management of such components. <a href="#filepos2185965">Figure 13.1</a> depicts how all these components fit together within the BI framework.</p>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><span class="calibre14"><a id="filepos2185965"></a>
<span class="calibre14">FIGURE 13.1 Business intelligence framework</span></span></span></p><div class="calibre58"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00492.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre73"><span class="calibre8">SOURCE: Course Technology/Cengage Learning</span></p><div class="calibre13"> </div>
<hr class="calibre10"/><p class="calibre9">The general BI framework depicted in <a href="#filepos2185965">Figure 13.1</a> has six basic components that encompass the functionality required on most current-generation BI systems. You will learn more about these components later in this chapter. The components are briefly described in <a href="#filepos2186807">Table 13.2</a>.</p>
<p class="calibre48"> </p>
<hr class="calibre10"/><p class="calibre63"><span class="calibre8"><span class="calibre14"><a id="filepos2186807"></a><span class="calibre14">TABLE 13.2 Basic BI Architectural Components</span></span></span></p><div class="calibre64"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00493.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre9">Each BI component shown in <a href="#filepos2186807">Table 13.2</a> has generated a fast-growing market for specialized tools. Thanks to technological advancements, the components can interact with other components to form a truly open architecture. As a matter of fact, you can integrate multiple tools from different vendors into a single BI framework. <a href="#filepos2187622">Table 13.3</a> shows a sample of common BI tools and vendors.</p>
<p class="calibre48"> </p>
<hr class="calibre10"/><p class="calibre63"><span class="calibre8"><span class="calibre14"><a id="filepos2187622"></a><span class="calibre14">TABLE 13.3 Sample of Business Intelligence Tools</span></span></span></p><div class="calibre64"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00494.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<hr class="calibre10"/><p class="calibre63">N<span><span class="calibre8">OTE</span></span></p>
<hr class="calibre10"/><blockquote class="calibre38"><p class="calibre53">You will learn about data warehouses, data mining, and OLAP tools later in this chapter.</p></blockquote>
<hr class="calibre10"/><p class="calibre9">As depicted in <a href="#filepos2176405">Figure 13.1</a>, BI integrates people and processes using technology to add value to the business. Such value is derived from how end users apply such information in their daily activities, and particularly in their daily business decision making.</p>
<p class="calibre9">The focus of traditional information systems was on operational automation and reporting; in contrast, BI tools focus on the strategic and tactical use of information. To achieve this goal, BI recognizes that technology alone is not enough. Therefore, BI uses an arrangement of best management practices to manage data as a corporate asset. One of the most recent developments in this area is the use of master data management techniques. <a id="filepos2188972"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2820670">Master data management (MDM)</a> is a collection of concepts, techniques, and processes for the proper identification, definition, and management of data elements within an organization. MDM’s main goal is to provide a comprehensive and consistent definition of all data within an organization. MDM ensures that all company resources (people, procedures, and IT systems) that work with data have uniform and consistent views of the company’s data.</p>
<p class="calibre9">An added benefit of this meticulous approach to data management and decision making is that it provides a framework for business governance. <a id="filepos2189660"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2798646">Governance</a> is a method or process of government. In this case, BI provides a method for controlling and monitoring business health and for consistent decision making. Furthermore, having such governance creates accountability for business decisions. In the present age of business flux, accountability is increasingly important. Had governance been as pivotal to business operations a few years back, crises precipitated by Enron, WorldCom, Arthur Andersen, and the 2008 financial meltdown might have been avoided.</p>
<p class="calibre9">Monitoring a business’s health is crucial to understanding where the company is and where it is headed. To do this, BI makes extensive use of a special type of metrics known as key performance indicators. <a id="filepos2190483"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2813974">Key performance indicators (KPIs)</a> are quantifiable numeric or scale-based measurements that assess the company’s effectiveness or success in reaching its strategic and operational goals. Many different KPIs are used by different industries. Some examples of KPIs are:</p>
<p class="calibre70">     •    <span class="italic">General</span>. Year-to-year measurements of profit by line of business, same-store sales, product turnovers, product recalls, sales by promotion, and sales by employee</p><div class="calibre3"> </div>
<p class="calibre71">     •    <span class="italic">Finance</span>. Earnings per share, profit margin, revenue per employee, percentage of sales to account receivables, and assets to sales</p><div class="calibre58"> </div>
<p class="calibre71">     •    <span class="italic">Human resources</span>. Applicants to job openings, employee turnover, and employee longevity</p><div class="calibre58"> </div>
<p class="calibre72">     •     <span class="italic">Education</span>. Graduation rates, number of incoming freshmen, student retention rates, publication rates, and teaching evaluation scores</p>
<p class="calibre9">KPIs are determined after the main strategic, tactical, and operational goals are defined for a business. To tie the KPI to the strategic master plan of an organization, a KPI is compared to a desired goal within a specific time frame. For example, if you are in an academic environment, you might be interested in ways to measure student satisfaction or retention. In this case, a sample goal would be to increase the final exam grades of graduating high school seniors by fall 2015. Another sample KPI would be to increase the returning student rate from freshman year to sophomore year from 60 percent to 75 percent by 2015. In this case, such performance indicators would be measured and monitored on a year-to-year basis, and plans to achieve such goals would be set in place.</p>
<p class="calibre9">Although BI has an unquestionably important role in modern business operations, the manager must initiate the decision support process by asking the appropriate questions. The BI environment exists to support the manager; it does not replace the management function. If the manager fails to ask the appropriate questions, problems will not be identified and solved, and opportunities will be missed. In spite of the very powerful BI presence, the human component is still at the center of business technology.</p>
<p class="calibre9">The main BI architectural components were illustrated in <a href="#filepos2185965">Figure 13.1</a> and further explained in <a href="#filepos2186807">Tables 13.2</a> and <a href="#filepos2187622">13.3</a>. However, the heart of the BI system is its advanced information generation and decision support capabilities. A BI system’s advanced decision support functions come to life via its intuitive and informational user interface, and particularly its reporting capabilities. A modern BI system provides three distinctive reporting styles:</p>
<p class="calibre70">     •    <span class="italic">Advanced reporting</span>. A BI system presents insightful information about the organization in a variety of presentation formats. Furthermore, the reports provide interactive features that allow the end user to study the data from multiple points of view—from highly summarized to very detailed data. The reports present key actionable information used to support decision making.</p><div class="calibre3"> </div>
<p class="calibre71">     •    <span class="italic">Monitoring and alerting</span>. After a decision has been made, the BI system offers ways to monitor the decision’s outcome. The BI system provides the end user with ways to define metrics and other key performance indicators to evaluate different aspects of an organization. In addition, exceptions and alerts can be set to warn managers promptly about deviations or problem areas.</p><div class="calibre58"> </div>
<p class="calibre72">     •     <span class="italic">Advanced data analytics</span>. A BI system provides tools to help the end user discover relationships, patterns, and trends hidden within the organization’s data. These tools are used to create two types of data analysis: explanatory and predictive. Explanatory analysis provides ways to discover relationships, trends, and patterns among data, while predictive analysis provides the end user with ways to create models that predict future outcomes.</p>
<p class="calibre9">Understanding the architectural components of a BI framework is the first step in properly implementing BI in an organization. A good BI infrastructure promises many benefits to an organization, as outlined in the next section.</p>
<p class="calibre69"><span class="calibre8"><a id="filepos2195495"></a><span class="calibre14">13.2.2 B<span><span class="calibre5">USINESS</span></span> I<span><span class="calibre5">NTELLIGENCE</span></span> B<span><span class="calibre5">ENEFITS</span></span></span></span></p>
<hr class="calibre10"/><p class="calibre9">As you have learned in previous sections, a properly implemented BI architecture could provide a framework for continuous performance improvements and business decision making. Improved decision making is the main goal of BI, but BI provides other benefits:</p>
<p class="calibre70">     •    <span class="italic">Integrating architecture</span>. Like any other IT project, BI has the potential of becoming the integrating umbrella for a disparate mix of IT systems within an organization. This architecture could support all types of company-generated data from operational to executive, as well as diverse hardware such as mainframes, servers, desktops for managers and executives, and mobile devices on the shop floor.</p><div class="calibre3"> </div>
<p class="calibre71">     •    <span class="italic">Common user interface for data reporting and analysis</span>. BI front ends can provide up-to-the-minute consolidated information using a common interface for all company users. IT departments no longer have to provide multiple training options for diverse interfaces. End users benefit from similar or common interfaces in different devices that use multiple clever and insightful presentation formats.</p><div class="calibre58"> </div>
<p class="calibre71">     •    <span class="italic">Common data repository fosters single version of company data</span>. In the past, multiple IT systems supported different aspects of an organization’s operations. Such systems collected and stored data in separate data stores. Keeping the data synchronized and up to date has always been difficult. BI provides a framework to integrate such data under a common environment and present a single version of the data.</p><div class="calibre58"> </div>
<p class="calibre72">     •     <span class="italic">Improved organizational performance</span>. BI can provide competitive advantages in many different areas, from customer support to manufacturing processes. Such advantages can be reflected in added efficiency, reduced waste, increased sales, reduced employee and customer turnover, and most importantly, an increased bottom line for the business.</p>
<p class="calibre9">Achieving all these benefits takes a lot of human, financial, and technological resources, not to mention time. BI benefits are not achieved overnight, but are the result of a focused company-wide effort that could take a long time. As a matter of fact, as you will learn in the next section, the BI field has evolved over a long period of time itself.</p>
<p class="calibre69"><span class="calibre8"><a id="filepos2198377"></a><span class="calibre14">13.2.3 B<span><span class="calibre5">USINESS</span></span> I<span><span class="calibre5">NTELLIGENCE</span></span> E<span><span class="calibre5">VOLUTION</span></span></span></span></p>
<hr class="calibre10"/><p class="calibre9">Providing useful information to end users has been a priority of IT systems since mainframe computing became an integral part of corporations. Business decision support has evolved over many decades. Following computer technology advances, business intelligence started with centralized reporting systems and evolved into today’s highly integrated BI environments. <a href="#filepos2199190">Table 13.4</a> summarizes the evolution of BI systems.</p>
<p class="calibre48"> </p>
<hr class="calibre10"/><p class="calibre63"><span class="calibre8"><span class="calibre14"><a id="filepos2199190"></a><span class="calibre14">TABLE 13.4 Business Intelligence Evolution</span></span></span></p><div class="calibre64"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00495.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre9">Using <a href="#filepos2199190">Table 13.4</a> as a guide, you can trace business intelligence from the mainframe environment to the desktop and then to the more current cloud-based, mobile BI environments. (<a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_034.html#filepos2380492">Chapter 14</a>, Database Connectivity and Web Technologies, provides a detailed discussion of cloud-based systems.)</p>
<p class="calibre9">The precursor of the modern BI environment was the first-generation decision support system. A <a id="filepos2199944"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2771475">decision support system (DSS)</a> is an arrangement of computerized tools used to assist managerial decision making. A DSS typically has a much narrower focus and reach than a BI solution. At first, decision support systems were the realm of a few selected managers in an organization. Over time, and with the introduction of the desktop computer, decision support systems migrated to more agile platforms, such as minicomputers, high-end servers, commodity servers, appliances, and cloud-based offerings. This evolution effectively changed the reach of decision support systems; BI is no longer limited to a small group of top-level managers with training in statistical modeling. Instead, BI is now available to all users in an organization, from line managers to the shop floor to mobile agents in the field.</p>
<p class="calibre9">You can also use <a href="#filepos2199190">Table 13.4</a> to track the evolution of information dissemination styles used in business intelligence.</p>
<p class="calibre70">     •    Starting in the late 1970s, the need for information distribution was filled by centralized reports running on mainframes, minicomputers, or even central server environments. Such reports were predefined and took considerable time to process.</p><div class="calibre3"> </div>
<p class="calibre71">     •    With the introduction of desktop computers in the 1980s, a new style of information distribution, the spreadsheet, emerged as the dominant format for decision support systems. In this environment, managers downloaded information from centralized data stores and manipulated the data in desktop spreadsheets.</p><div class="calibre58"> </div>
<p class="calibre71">     •    As the use of spreadsheets multiplied, IT departments tried to manage the flow of data in a more formal way using enterprise reporting systems. These systems were developed in the early 1990s and basically integrated all data into an IT umbrella that started with the first-generation DSS. The systems still used spreadsheet-like features with which end users were familiar.</p><div class="calibre58"> </div>
<p class="calibre71">     •    Once DSSs were established, the evolution of business intelligence flourished with the introduction of the data warehouse and online analytical processing systems (OLAPs) in the mid-1990s.</p><div class="calibre58"> </div>
<p class="calibre72">     •     Rapid changes in information technology and the Internet revolution led to the introduction of advanced BI systems such as Web-based dashboards in the early 2000s and mobile BI later in the decade. With mobile BI, end users access BI reports via native applications that run on a mobile smart device, such as the iPhone, Blackberry, or iPad.</p>
<p class="calibre9"><a href="#filepos2203095">Figure 13.2</a> depicts the evolution of BI information dissemination.</p>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><span class="calibre14"><a id="filepos2203095"></a><span class="calibre14">FIGURE 13.2 Evolution of BI information dissemination formats</span></span></span></p><div class="calibre58"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00496.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre63">Credit: Oleksiy Mark / <a href="http://Shutterstock.com">Shutterstock.com</a></p>
<p class="calibre22"><span class="calibre8">SOURCE: Course Technology/Cengage Learning</span></p><div class="calibre13"> </div>
<p class="calibre48"> </p>
<hr class="calibre10"/><p class="calibre63">N<span><span class="calibre8">OTE</span></span></p>
<hr class="calibre10"/><blockquote class="calibre38"><p class="calibre53">The OLAP environment is covered in <a href="#filepos2292235">Section 13.7</a> of this chapter.</p></blockquote>
<hr class="calibre10"/><p class="calibre9">Although now in its infancy, mobile BI technology is poised to have a significant impact on the way BI information is disseminated and processed. If the number of students using smart phones to communicate with friends, update their Facebook status, and send tweets on Twitter is any indicator, you can expect the next generation of consumers and workers to be highly mobile. Leading corporations are therefore starting to push decision making to agents in the field to facilitate customer relationships, sales and ordering, and product support. Such mobile technologies are so portable and interactive that some users call them “disruptive” technologies.</p>
<p class="calibre9">BI information technology has evolved from centralized reporting styles to the current, mobile BI style in just over a decade. The rate of technological change is not slowing down; to the contrary, technology advancements are accelerating the adoption of BI to new levels. The next section illustrates some BI technology trends.</p>
<p class="calibre69"><span class="calibre8"><a id="filepos2205104"></a><span class="calibre14">13.2.4 B<span><span class="calibre5">USINESS</span></span> I<span><span class="calibre5">NTELLIGENCE</span></span> T<span><span class="calibre5">ECHNOLOGY</span></span> T<span><span class="calibre5">RENDS</span></span></span></span></p>
<hr class="calibre10"/><p class="calibre9">Several technological advances are driving the growth of business intelligence technologies. These advances create new generations of more affordable products and services that are faster and easier to use. In turn, such products and services open new markets and work as driving forces in the increasing adoption of business intelligence technologies within organizations. Some of the more remarkable technological trends are:</p>
<p class="calibre70">     •    <span class="italic">Data storage improvements</span>. New data storage technologies, such as solid state drives (SSD) and Serial Advanced Technology Attachment (SATA) drives, offer increased performance and larger capacity that make data storage faster and more affordable. Currently you can buy single drives with a capacity approaching four terabytes.</p><div class="calibre3"> </div>
<p class="calibre71">     •    <span class="italic">Business intelligence appliances</span>. Vendors now offer plug-and-play appliances optimized for data warehouse and BI applications. These new appliances offer improved price-performance ratios, simplified administration, rapid installation, scalability, and fast integration. Examples of these vendors include IBM, Netezza, Greenplum, and AsterData.</p><div class="calibre58"> </div>
<p class="calibre71">     •    <span class="italic">Business intelligence as a service</span>. Companies are starting to offer data warehouses and BI as a service. These cloud-based services allow any corporation to rapidly develop a data warehouse store without the need for hardware, software, or extra personnel. These prepackaged services offer “pay-as-you-go” models for specific industries and capacities, and they provide an opportunity for organizations to pilot-test a BI project without incurring large time or cost commitments. Such services are offered by Netezza, AppNexus, AsterData, MicroStrategy, and Kognitio.</p><div class="calibre58"> </div>
<p class="calibre71">     •    <span class="italic">Big Data analytics</span>. In <a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_012.html#filepos268583">Chapter 2</a>, Data Models, you learned about Big Data and column-store databases. The Big Data phenomenon is creating a new market for data analytics. Organizations are turning to social media as the new source for information and knowledge to gain competitive advantages. Examples of Big Data analytics vendors include Vertica, AsterData, and Netezza.</p><div class="calibre58"> </div>
<p class="calibre72">     •     <span class="italic">Personal analytics</span>. OLAP brought data analytics to the desktop of every end user in an organization. Mobile BI is extending business decision making outside the walls of the organization. BI can now be deployed to mobile users who are closer to customers. The main requirement is for the BI end user to have a key understanding of the business. Examples of personal analytics vendors include MicroStrategy, QlikView, and Actuate.</p>
<p class="calibre9">One constant in this relentless technological evolution is the need for better decision support data and the importance of understanding the difference between decision support data and operational data.</p>
<p class="calibre33"> </p>
<hr class="calibre10"/><p class="calibre22"><span class="calibre35"><a id="filepos2208747"></a>13.3 D<span><span class="calibre68">ECISION</span></span> S<span><span class="calibre68">UPPORT</span></span> D<span><span class="calibre68">ATA</span></span></span></p>
<hr class="calibre10"/><p class="calibre9">Although BI is used at strategic and tactical managerial levels within organizations, <span class="italic">its effectiveness depends on the quality of data gathered at the operational level</span>. Yet, operational data are seldom well suited to the decision support tasks. The differences between operational data and decision support data are examined in the next section.</p>
<p class="calibre69"><span class="calibre8"><a id="filepos2209391"></a><span class="calibre14">13.3.1 O<span><span class="calibre5">PERATIONAL</span></span> D<span><span class="calibre5">ATA VS.</span></span> D<span><span class="calibre5">ECISION</span></span> S<span><span class="calibre5">UPPORT</span></span> D<span><span class="calibre5">ATA</span></span></span></span></p>
<hr class="calibre10"/><p class="calibre9">Operational data and decision support data serve different purposes. Therefore, it is not surprising to learn that their formats and structures differ. Most operational data are stored in a relational database in which the structures (tables) tend to be highly normalized. Operational data storage is optimized to support transactions that represent daily operations. For example, each time an item is sold, it must be accounted for. Customer data, inventory data, and other similar data need frequent updating. To provide effective update performance, operational systems store data in many tables, each with a minimum number of fields. Thus, a simple sales transaction might be represented by five or more different tables, such as INVOICE, INVOICE LINE, DISCOUNT, STORE, and DEPARTMENT. Although such an arrangement is excellent in an operational database, it is not efficient for query processing. For example, to extract a simple invoice, you would have to join several tables. Whereas operational data are useful for capturing daily business transactions, decision support data give tactical and strategic business meaning to the operational data. From the data analyst’s point of view, decision support data differ from operational data in three main areas: time span, granularity, and dimensionality.</p>
<p class="calibre70">     •    <span class="italic">Time span</span>. Operational data cover a short time frame. In contrast, decision support data tend to cover a longer time frame. Managers are seldom interested in a specific sales invoice to customer X; rather, they tend to focus on sales generated during the last month, the last year, or the last five years.</p><div class="calibre3"> </div>
<p class="calibre71">     •    <span class="italic">Granularity (level of aggregation)</span>. Decision support data must be presented at different levels of aggregation, from highly summarized to nearly atomic. For example, if managers analyze regional sales, they must be able to access data showing the sales by region, by city within the region, by store within the city within the region, and so on. In that case, summarized data to compare the regions is required, along with data in a structure that enables a manager to <a id="filepos2211969"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2780312">drill down</a>, or decompose, the data into more atomic components—that is, finergrained data at lower levels of aggregation. In contrast, when you <a id="filepos2212147"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2855395">roll up</a> the data, you are aggregating the data to a higher level.</p><div class="calibre58"> </div>
<p class="calibre72">     •     <span class="italic">Dimensionality</span>. Operational data focus on representing individual transactions rather than the effects of the transactions over time. In contrast, data analysts tend to include many data dimensions and are interested in how the data relate over those dimensions. For example, an analyst might want to know how product X fared relative to product Z during the past six months by region, state, city, store, and customer. In that case, both place and time are part of the picture.</p>
<p class="calibre9"><a href="#filepos2213337">Figure 13.3</a> shows how decision support data can be examined from multiple dimensions such as product, region, and year, using a variety of filters to produce each dimension. The ability to analyze, extract, and present information in meaningful ways is one of the differences between decision support data and transaction-at-a-time operational data.</p>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><span class="calibre14"><a id="filepos2213337"></a><span class="calibre14">FIGURE 13.3 Transforming operational data into decision support data</span></span></span></p><div class="calibre58"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00497.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre73"><span class="calibre8">SOURCE: Course Technology/Cengage Learning</span></p><div class="calibre13"> </div>
<hr class="calibre10"/><hr class="calibre10"/><p class="calibre63"><span class="calibre35"><img alt="img" src="images/00023.jpg" class="calibre7"/> O<span><span class="calibre68">NLINE</span></span> C<span><span class="calibre68">ONTENT</span></span></span></p>
<p class="calibre9">The operational data in <a href="#filepos2213337">Figure 13.3</a> are available at <a href="http://www.cengagebrain.com"><span class="italic">www.cengagebrain.com</span></a>. The decision support data in <a href="#filepos2213337">Figure 13.3</a> show the output for the solution to <a href="#filepos2362318">Problem 2</a> at the end of this chapter.</p>
<hr class="calibre10"/><p class="calibre9">From the designer’s point of view, the differences between operational and decision support data are as follows:</p>
<p class="calibre70">     •    Operational data represent transactions as they happen in real time. Decision support data are a snapshot of the operational data at a given point in time. Therefore, decision support data are historic, representing a time slice of the operational data.</p><div class="calibre3"> </div>
<p class="calibre71">     •    Operational and decision support data are different in terms of transaction <span class="italic">type</span> and transaction <span class="italic">volume</span>. Whereas operational data are characterized by update transactions, decision support data are mainly characterized by read-only transactions. Decision support data also require <span class="italic">periodic</span> updates to load new data that are summarized from the operational data. Finally, the concurrent transaction volume in operational data tends to be very high compared with the low to medium levels in decision support data.</p><div class="calibre58"> </div>
<p class="calibre71">     •    Operational data are commonly stored in many tables, and the stored data represent information about a given transaction only. Decision support data are generally stored in a few tables derived from the operational data. The decision support data do not include the details of each operational transaction. Instead, decision support data represent transaction <span class="italic">summaries;</span> therefore, the decision support database stores data that are integrated, aggregated, and summarized for decision support purposes.</p><div class="calibre58"> </div>
<p class="calibre71">     •    The degree to which decision support data are summarized is very high when contrasted with operational data. Therefore, you will see a great deal of derived data in decision support databases. For example, rather than storing all 10,000 sales transactions for a given store on a given day, the decision support database might simply store the total number of units sold and the total sales dollars generated during that day. Decision support data might be collected to monitor such aggregates as total sales for each store or for each product. The purpose of the summaries is simple: they are used to establish and evaluate sales trends and product sales comparisons, and to provide other data that serve decision needs. (How well are items selling? Should this product be discontinued? Has the advertising been effective as measured by increased sales?)</p><div class="calibre58"> </div>
<p class="calibre71">     •    The data models that govern operational data and decision support data are different. The operational database’s frequent and rapid data updates make data anomalies a potentially devastating problem. Therefore, the data in a relational transaction (operational) system generally require normalized structures that yield many tables, each of which contains the minimum number of attributes. In contrast, the decision support database is not subject to such transaction updates, and the focus is on querying capability. Therefore, decision support databases tend to be non-normalized and include few tables, each of which contains a large number of attributes.</p><div class="calibre58"> </div>
<p class="calibre71">     •    The frequency and complexity of query activity in the operational database tends to be low to allow additional processing cycles for the more crucial update transactions. Therefore, queries against operational data typically are narrow in scope and low in complexity, and high speed is critical. In contrast, decision support data exist for the sole purpose of serving query requirements. Queries against decision support data typically are broad in scope and high in complexity, and less speed is needed.</p><div class="calibre58"> </div>
<p class="calibre72">     •     Finally, decision support data are characterized by very large amounts of data. The large data volume is the result of two factors. First, data are stored in non-normalized structures that are likely to display many data redundancies and duplications. Second, the same data can be categorized in many different ways to represent different snapshots. For example, sales data might be stored in relation to product, store, customer, region, and manager.</p>
<p class="calibre9"><a href="#filepos2219131">Table 13.5</a> summarizes the differences between operational and decision support data from the database designer’s point of view.</p>
<p class="calibre48"> </p>
<hr class="calibre10"/><p class="calibre63"><span class="calibre8"><span class="calibre14"><a id="filepos2219131"></a><span class="calibre14">TABLE 13.5 Contrasting Operational and Decision Support Data Characteristics</span></span></span></p><div class="calibre64"> </div>
<hr class="calibre10"/><div class="calibre58"> </div><table class="calibre59"><div class="calibre5">
<tr class="calibre61"><td class="calibre62"><p class="calibre63">CHARACTERISTIC</p></td><td class="calibre62"><p class="calibre63">OPERATIONAL DATA</p></td><td class="calibre62"><p class="calibre63">DECISION SUPPORT DATA</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">Data currency</p></td><td class="calibre62"><p class="calibre63">Current operations</p><p class="calibre63">Real-time data</p></td><td class="calibre62"><p class="calibre63">Historic data</p><p class="calibre63">Snapshot of company data</p><p class="calibre63">Time component (week/month/year)</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">Granularity</p></td><td class="calibre62"><p class="calibre63">Atomic-detailed data</p></td><td class="calibre62"><p class="calibre63">Summarized data</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">Summarization level</p></td><td class="calibre62"><p class="calibre63">Low; some aggregate yields</p></td><td class="calibre62"><p class="calibre63">High; many aggregation levels</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">Data model</p></td><td class="calibre62"><p class="calibre63">Highly normalized</p><p class="calibre63">Mostly relational DBMSs</p></td><td class="calibre62"><p class="calibre63">Non-normalized</p><p class="calibre63">Complex structures</p><p class="calibre63">Some relational, but mostly multidimensional DBMSs</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">Transaction type</p></td><td class="calibre62"><p class="calibre63">Mostly updates</p></td><td class="calibre62"><p class="calibre63">Mostly query</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">Transaction volumes</p></td><td class="calibre62"><p class="calibre63">High update volumes</p></td><td class="calibre62"><p class="calibre63">Periodic loads and summary calculations</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">Transaction speed</p></td><td class="calibre62"><p class="calibre63">Updates are critical</p></td><td class="calibre62"><p class="calibre63">Retrievals are critical</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">Query activity</p></td><td class="calibre62"><p class="calibre63">Low to medium</p></td><td class="calibre62"><p class="calibre63">High</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">Query scope</p></td><td class="calibre62"><p class="calibre63">Narrow range</p></td><td class="calibre62"><p class="calibre63">Broad range</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">Query complexity</p></td><td class="calibre62"><p class="calibre63">Simple to medium</p></td><td class="calibre62"><p class="calibre63">Very complex</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">Data volumes</p></td><td class="calibre62"><p class="calibre63">Hundreds of gigabytes</p></td><td class="calibre62"><p class="calibre63">Terabytes to petabytes</p></td></tr></div></table><div class="calibre64"> </div>
<hr class="calibre10"/><p class="calibre9">The many differences between operational data and decision support data are good indicators of decision support database requirements, which are described in the next section.</p>
<p class="calibre69"><span class="calibre8"><a id="filepos2223030"></a>13.3.2 D<span><span class="calibre5">ECISION</span></span> S<span><span class="calibre5">UPPORT</span></span> D<span><span class="calibre5">ATABASE</span></span> R<span><span class="calibre5">EQUIREMENTS</span></span></span></p>
<hr class="calibre10"/><p class="calibre9">A decision support database is a specialized DBMS tailored to provide fast answers to complex queries. There are three main requirements for a decision support database: the database schema, data extraction and filtering, and database size.</p>
<p class="calibre83"><span class="calibre5"><span class="calibre14">Database Schema</span></span></p>
<p class="calibre53">The decision support database schema must support complex (non-normalized) data representations. As noted earlier, the decision support database must contain data that are aggregated and summarized. In addition to meeting those requirements, the queries must be able to extract multidimensional time slices. If you are using an RDBMS, the conditions suggest using non-normalized and even duplicated data. To see why this must be true, take a look at the 10-year sales history for a single store containing a single department. At this point, the data are fully normalized within the single table, as shown in <a href="#filepos2224490">Table 13.6</a>.</p>
<p class="calibre48"> </p>
<hr class="calibre10"/><p class="calibre63"><span class="calibre8"><span class="calibre14"><a id="filepos2224490"></a><span class="calibre14">TABLE 13.6 Ten-Year Sales History for a Single Department, in Millions of Dollars</span></span></span></p><div class="calibre64"> </div>
<hr class="calibre10"/><div class="calibre58"> </div><table class="calibre59"><div class="calibre5">
<tr class="calibre61"><td class="calibre62"><p class="calibre63"><span class="calibre14">YEAR</span></p></td><td class="calibre62"><p class="calibre63"><span class="calibre14">SALES</span></p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">2002</p></td><td class="calibre62"><p class="calibre63">8,227</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">2003</p></td><td class="calibre62"><p class="calibre63">9,109</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">2004</p></td><td class="calibre62"><p class="calibre63">10,104</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">2005</p></td><td class="calibre62"><p class="calibre63">11,553</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">2006</p></td><td class="calibre62"><p class="calibre63">10,018</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">2007</p></td><td class="calibre62"><p class="calibre63">11,875</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">2008</p></td><td class="calibre62"><p class="calibre63">12,699</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">2009</p></td><td class="calibre62"><p class="calibre63">14,875</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">2010</p></td><td class="calibre62"><p class="calibre63">16,301</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">2011</p></td><td class="calibre62"><p class="calibre63">19,986</p></td></tr></div></table><div class="calibre64"> </div>
<hr class="calibre10"/><p class="calibre9">This structure works well when you have only one store with only one department. However, it is very unlikely that such a simple environment has much need for a decision support database. A decision support database becomes a factor when you are dealing with more than one store, each of which has more than one department. To support all of the decision support requirements, the database must contain data for all of the stores and all of their departments—and the database must be able to support multidimensional queries that track sales by stores, by departments, and over time. For simplicity, suppose that there are only two stores (A and B) and two departments (1 and 2) within each store. Also, change the time dimension to include yearly data. <a href="#filepos2227596">TABLE 13.7</a> shows the sales figures under the specified conditions. Only 2002, 2006, and 2011 are shown; ellipses (…) are used to indicate that data values were omitted. You can see in <a href="#filepos2227596">Table 13.7</a> that the number of rows and attributes already multiplies quickly and that the table exhibits multiple redundancies.</p>
<p class="calibre48"> </p>
<hr class="calibre10"/><p class="calibre63"><span class="calibre8"><span class="calibre14"><a id="filepos2227596"></a><span class="calibre14">TABLE 13.7 Yearly Sales Summaries, Two Stores and Two Departments per Store, in Millions of Dollars</span></span></span></p><div class="calibre64"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00498.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre9">Now suppose that the company has 10 departments per store and 20 stores nationwide, and suppose that you want to access yearly sales summaries. Now you are dealing with 200 rows and 12 monthly sales attributes per row. (Actually, there are 13 attributes per row if you add each store’s sales total for each year.)</p>
<p class="calibre9">The decision support database schema must also be optimized for query (read-only) retrievals. To optimize query speed, the DBMS must support features such as bitmap indexes and data partitioning. In addition, the DBMS query optimizer must be enhanced to support the non-normalized and complex structures in decision support databases.</p>
<p class="calibre83"><span class="calibre5"><span class="calibre14">Data Extraction and Filtering</span></span></p>
<p class="calibre53">The decision support database is created largely by extracting data from the operational database and by importing additional data from external sources. Thus, the DBMS must support advanced data extraction and data-filtering tools. To minimize the impact on the operational database, the data extraction capabilities should allow batch and scheduled data extraction, and should support different data sources: flat files and hierarchical, network, and relational databases, as well as multiple vendors. Data-filtering capabilities must include the ability to check for inconsistent data or data validation rules. Finally, to filter and integrate the operational data into the decision support database, the DBMS must support advanced data integration, aggregation, and classification.</p>
<p class="calibre9">Using data from multiple external sources also usually means having to solve data-formatting conflicts. For example, data such as Social Security numbers and dates can occur in different formats; measurements can be based on different scales, and the same data elements can have different names. In short, data must be filtered and purified to ensure that only the pertinent decision support data are stored in the database and that they are stored in a standard format.</p>
<p class="calibre83"><span class="calibre5"><span class="calibre14">Database Size</span></span></p>
<p class="calibre53">Decision support databases tend to be very large; gigabyte and terabyte ranges are not unusual. For example, in 2008, Wal-Mart had more than four petabytes of data in its data warehouses. Therefore, the DBMS must be capable of supporting <a id="filepos2230525"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2887859">very large databases (VLDBs)</a>. To support a VLDB adequately, the DBMS might be required to support advanced storage technologies, and even more importantly, to support multiple-processor technologies, such as a symmetric multiprocessor (SMP) or a massively parallel processor (MPP).</p>
<p class="calibre9">The complex information requirements and the ever-growing demand for sophisticated data analysis sparked the creation of a new type of data repository. This repository, called a data warehouse, contains data in formats that facilitate data extraction, data analysis, and decision making. It has become the foundation for a new generation of decision support systems.</p>
<p class="calibre33"> </p>
<hr class="calibre10"/><p class="calibre22"><span class="calibre35"><a id="filepos2231434"></a>13.4 T<span><span class="calibre68">HE</span></span> D<span><span class="calibre68">ATA</span></span> W<span><span class="calibre68">AREHOUSE</span></span></span></p>
<hr class="calibre10"/><p class="calibre9">Bill Inmon, the acknowledged “father” of the <a id="filepos2231697"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2763700">data warehouse</a>, defines the term as “an <span class="italic">integrated, subject-oriented, time-variant, nonvolatile</span> collection of data that provides support for decision making.”<sup class="calibre56"><a href="#filepos2373820">2</a></sup> (Italics were added for emphasis.) To understand that definition, take a more detailed look at its components.</p>
<p class="calibre71">     •    <span class="italic">Integrated</span>. The data warehouse is a centralized, consolidated database that integrates data derived from the entire organization and from multiple sources with diverse formats. Data integration implies that all business entities, data elements, data characteristics, and business metrics are <span class="italic">described in the same way throughout the enterprise</span>. Although this requirement sounds logical, you would be amazed to discover how many different measurements for “sales performance” can exist within an organization; the same scenario can be true for any other business element. For instance, the status of an order might be indicated with text labels such as “open,” “received,” “canceled,” and “closed” in one department and as “1,” “2,” “3,” and “4” in another department. A student’s status might be defined as “freshman,” “sophomore,” “junior,” or “senior” in the accounting department and as “FR,” “SO,” “JR,” or “SR” in the computer information systems department. To avoid the potential format tangle, the data in the data warehouse must conform to a common format that is acceptable throughout the organization. This integration can be time-consuming, but once accomplished, it enhances decision making and helps managers better understand the company’s operations. This understanding can be translated into recognition of strategic business opportunities.</p><div class="calibre58"> </div>
<p class="calibre71">     •    <span class="italic">Subject-oriented</span>. Data warehouse data are arranged and optimized to provide answers to questions from diverse functional areas within a company. Data warehouse data are organized and summarized by topic, such as sales, marketing, finance, distribution, and transportation. For each topic, the data warehouse contains specific subjects of interest—products, customers, departments, regions, promotions, and so on. This form of data organization is quite different from the more functional or process-oriented organization of typical transaction systems. For example, an invoicing system designer concentrates on designing normalized data structures to support the business process by storing invoice components in two tables: INVOICE and INVLINE. In contrast, the data warehouse has a <span class="italic">subject</span> orientation. Data warehouse designers focus specifically on the data rather than on the processes that modify the data. (After all, data warehouse data are not subject to numerous realtime data updates!) Therefore, instead of storing an invoice, the data warehouse stores its “sales by product” and “sales by customer” components because decision support activities require the retrieval of sales summaries by product or customer.</p><div class="calibre58"> </div>
<p class="calibre71">     •    <span class="italic">Time-variant</span>. In contrast to operational data, which focus on current transactions, warehouse data represent the flow of data through time. The data warehouse can even contain projected data generated through statistical and other models. It is also time-variant in the sense that when data are periodically uploaded to the data warehouse, all time-dependent aggregations are recomputed. For example, when data for previous weekly sales are uploaded to the data warehouse, the weekly, monthly, yearly, and other time-dependent aggregates for products, customers, stores, and other variables are also updated. Because data in a data warehouse constitute a snapshot of the company history as measured by its variables, the time component is crucial. The data warehouse contains a time ID that is used to generate summaries and aggregations by week, month, quarter, year, and so on. Once the data enter the data warehouse, the time ID assigned to the data cannot be changed.</p><div class="calibre58"> </div>
<p class="calibre72">     •     <span class="italic">Nonvolatile</span>. Once data enter the data warehouse, they are never removed. Because the data in the warehouse represent the company’s history, the operational data, which represent the near-term history, are always added to it. Because data are never deleted and new data are continually added, the data warehouse is always growing. Therefore, the DBMS must be able to support multiterabyte or greater databases operating on multiprocessor hardware.</p>
<p class="calibre9"><a href="#filepos2236721">Table 13.8</a> summarizes the differences between data warehouses and operational databases.</p>
<p class="calibre48"> </p>
<hr class="calibre10"/><p class="calibre63"><span class="calibre8"><span class="calibre14"><a id="filepos2236721"></a><span class="calibre14">TABLE 13.8 Characteristics of Data Warehouse Data and Operational Database Data</span></span></span></p><div class="calibre64"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00499.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre9">In summary, the data warehouse is a read-only database optimized for data analysis and query processing. Typically, data are extracted from various sources and are then transformed and integrated—in other words, passed through a data filter—before being loaded into the data warehouse. As mentioned, this process is known as ETL. <a href="#filepos2237529">Figure 13.4</a> illustrates the ETL process to create a data warehouse from operational data.</p>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><span class="calibre14"><a id="filepos2237529"></a><span class="calibre14">FIGURE 13.4 The ETL process</span></span></span></p><div class="calibre58"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00500.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre73"><span class="calibre8">SOURCE: Course Technology/Cengage Learning</span></p><div class="calibre13"> </div>
<hr class="calibre10"/><p class="calibre9">Although the centralized and integrated data warehouse can be an attractive proposition that yields many benefits, managers may be reluctant to embrace this strategy. Creating a data warehouse requires time, money, and considerable managerial effort. Therefore, it is not surprising that many companies begin their foray into data warehousing by focusing on more manageable data sets that are targeted to meet the special needs of small groups within the organization. These smaller data stores are called data marts.</p>
<p class="calibre69"><span class="calibre8"><a id="filepos2238484"></a>13.4.1 D<span><span class="calibre5">ATA</span></span> M<span><span class="calibre5">ARTS</span></span></span></p>
<hr class="calibre10"/><p class="calibre9">A <a id="filepos2238663"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2760284">data mart</a> is a small, single-subject data warehouse subset that provides decision support to a small group of people. In addition, a data mart could be created from data extracted from a larger data warehouse for the specific purpose of supporting faster data access to a target group or function. That is, data marts and data warehouses can coexist within a business intelligence environment.</p>
<p class="calibre9">Some organizations choose to implement data marts not only because of the lower cost and shorter implementation time but because of the technological advances and inevitable “people issues” that make data marts attractive. Powerful computers can provide a customized decision support system to small groups in ways that might not be possible with a centralized system. Also, a company’s culture may predispose its employees to resist major changes, but they might quickly embrace relatively minor changes that lead to demonstrably improved decision support. In addition, people at different organizational levels are likely to require data with different summarization, aggregation, and presentation formats. Data marts can serve as a test vehicle for companies exploring the potential benefits of data warehouses. By gradually migrating from data marts to data warehouses, a specific department’s decision support needs can be addressed within six months to one year, as opposed to the one- to three-year time frame usually required to implement a data warehouse. Information technology (IT) departments also benefit from this approach because their personnel can learn the issues and develop the skills required to create a data warehouse.</p>
<p class="calibre9">The only difference between a data mart and a data warehouse is the size and scope of the problem being solved. The problem definitions and data requirements are essentially the same for both. To be useful, the data warehouse must conform to uniform structures and formats to avoid data conflicts and support decision making.</p>
<p class="calibre69"><span class="calibre8"><a id="filepos2240866"></a>13.4.2 T<span><span class="calibre5">WELVE</span></span> R<span><span class="calibre5">ULES</span></span> T<span><span class="calibre5">HAT</span></span> D<span><span class="calibre5">EFINE A</span></span> D<span><span class="calibre5">ATA</span></span> W<span><span class="calibre5">AREHOUSE</span></span></span></p>
<hr class="calibre10"/><p class="calibre9">In 1994, Bill Inmon and Chuck Kelley created a set of rules to define a data warehouse. These rules summarize many of the points made in this chapter about data warehouses.<sup class="calibre56"><a href="#filepos2374092">3</a></sup> The 12 rules for a data warehouse are shown in <a href="#filepos2241642">Table 13.9</a>.</p>
<p class="calibre48"> </p>
<hr class="calibre10"/><p class="calibre63"><span class="calibre8"><span class="calibre14"><a id="filepos2241642"></a><span class="calibre14">TABLE 13.9 Twelve Rules for a Data Warehouse</span></span></span></p><div class="calibre64"> </div>
<hr class="calibre10"/><div class="calibre58"> </div><table class="calibre59"><div class="calibre5">
<tr class="calibre61"><td class="calibre62"><p class="calibre63"><span class="calibre14">RULE NO</span>.</p></td><td class="calibre62"><p class="calibre63"><span class="calibre14">DESCRIPTION</span></p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">1</p></td><td class="calibre62"><p class="calibre63">The data warehouse and operational environments are separated.</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">2</p></td><td class="calibre62"><p class="calibre63">The data warehouse data are integrated.</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">3</p></td><td class="calibre62"><p class="calibre63">The data warehouse contains historical data over a long time.</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">4</p></td><td class="calibre62"><p class="calibre63">The data warehouse data are snapshot data captured at a given point in time.</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">5</p></td><td class="calibre62"><p class="calibre63">The data warehouse data are subject oriented.</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">6</p></td><td class="calibre62"><p class="calibre63">The data warehouse data are mainly read-only with periodic batch updates from operational data. No online updates are allowed.</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">7</p></td><td class="calibre62"><p class="calibre63">The data warehouse development life cycle differs from classical systems development. Data warehouse development is data-driven; the classical approach is process-driven.</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">8</p></td><td class="calibre62"><p class="calibre63">The data warehouse contains data with several levels of detail: current detail data, old detail data, lightly summarized data, and highly summarized data.</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">9</p></td><td class="calibre62"><p class="calibre63">The data warehouse environment is characterized by read-only transactions to very large data sets. The operational environment is characterized by numerous update transactions to a few data entities at a time.</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">10</p></td><td class="calibre62"><p class="calibre63">The data warehouse environment has a system that traces data sources, transformations, and storage.</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">11</p></td><td class="calibre62"><p class="calibre63">The data warehouse’s metadata are a critical component of this environment. The metadata identify and define all data elements. The metadata provide the source, transformation, integration, storage, usage, relationships, and history of each data element.</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">12</p></td><td class="calibre62"><p class="calibre63">The data warehouse contains a chargeback mechanism for resource usage that enforces optimal use of the data by end users.</p></td></tr></div></table><div class="calibre64"> </div>
<hr class="calibre10"/><p class="calibre9">Note how the 12 rules capture the complete data warehouse life cycle—from its introduction as an entity separate from the operational data store to its components, functionality, and management processes.</p>
<p class="calibre9">Most data warehouse implementations are based on the relational database model, and their market share suggests that their popularity will not fade anytime soon. Relational data warehouses use the star schema design technique to handle multidimensional data.</p>
<p class="calibre33"> </p>
<hr class="calibre10"/><p class="calibre22"><span class="calibre35"><a id="filepos2245746"></a>13.5 S<span><span class="calibre68">TAR</span></span> S<span><span class="calibre68">CHEMAS</span></span></span></p>
<hr class="calibre10"/><p class="calibre9">The <a id="filepos2245927"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2868248">star schema</a> is a data-modeling technique used to map multidimensional decision support data into a relational database. In effect, the star schema creates the near equivalent of a multidimensional database schema from the existing relational database. Star schemas yield an easily implemented model for multidimensional data analysis while preserving the relational structures on which the operational database is built. The basic star schema has four components: facts, dimensions, attributes, and attribute hierarchies.</p>
<p class="calibre69"><span class="calibre8"><a id="filepos2246552"></a>13.5.1 F<span><span class="calibre5">ACTS</span></span></span></p>
<hr class="calibre10"/><p class="calibre9"><a id="filepos2246689"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2791771">Facts</a> are numeric measurements (values) that represent a specific business aspect or activity. For example, sales figures are numeric measurements that represent product and service sales. Facts commonly used in business data analysis are units, costs, prices, and revenues. Facts are normally stored in a <a id="filepos2247029"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2791443">fact table</a> that is the center of the star schema. The fact table contains facts that are linked through their dimensions, which are explained in the next section.</p>
<p class="calibre9">Facts can also be computed or derived at run time. Such computed or derived facts are sometimes called <a id="filepos2247398"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2822172">metrics</a> to differentiate them from stored facts. The fact table is updated periodically with data from operational databases.</p>
<p class="calibre69"><span class="calibre8"><a id="filepos2247627"></a>13.5.2 D<span><span class="calibre5">IMENSIONS</span></span></span></p>
<hr class="calibre10"/><p class="calibre9"><a id="filepos2247769"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2775442">Dimensions</a> are qualifying characteristics that provide additional perspectives to a given fact. Recall that dimensions are of interest because <span class="italic">decision support data are almost always viewed in relation to other data</span>. For instance, sales might be compared by product from region to region and from one time period to the next. The kind of problem typically addressed by a BI system might be to compare the sales of unit X by region for the first quarters of 2002 through 2012. In that example, sales have product, location, and time dimensions. In effect, dimensions are the magnifying glass through which you study the facts. Such dimensions are normally stored in <a id="filepos2248475"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2775147">dimension tables</a>. <a href="#filepos2248721">Figure 13.5</a> depicts a star schema for sales with product, location, and time dimensions.</p>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><span class="calibre14"><a id="filepos2248721"></a><span class="calibre14">FIGURE 13.5 Simple star schema</span></span></span></p><div class="calibre58"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00501.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre73"><span class="calibre8">SOURCE: Course Technology/Cengage Learning</span></p><div class="calibre13"> </div>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><a id="filepos2249092"></a>13.5.3 A<span><span class="calibre5">TTRIBUTES</span></span></span></p>
<hr class="calibre10"/><p class="calibre9">Each dimension table contains attributes. Attributes are often used to search, filter, or classify facts. <span class="italic">Dimensions provide descriptive characteristics about the facts through their attributes</span>. Therefore, the data warehouse designer must define common business attributes that will be used by the data analyst to narrow a search, group information, or describe dimensions. Using a sales example, some possible attributes for each dimension are illustrated in <a href="#filepos2249871">Table 13.10</a>.</p>
<p class="calibre48"> </p>
<hr class="calibre10"/><p class="calibre63"><span class="calibre8"><span class="calibre14"><a id="filepos2249871"></a><span class="calibre14">TABLE 13.10 Possible Attributes for Sales Dimensions</span></span></span></p><div class="calibre64"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00502.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre9">These product, location, and time dimensions add a business perspective to the sales facts. The data analyst can now group the sales figures for a given product, in a given region, and at a given time. The star schema, through its facts and dimensions, can provide the data in a format suited for data analysis. Also, it can do so without imposing the burden of additional and unnecessary data, such as order number, purchase order number, and status, that commonly exist in operational databases.</p>
<p class="calibre9">Conceptually, the sales example’s multidimensional data model is best represented by a three-dimensional cube. Of course, this does not imply that there is a limit on the number of dimensions you can associate to a fact table. There is no mathematical limit to the number of dimensions used. However, using a three-dimensional model makes it easy to visualize the problem. The three-dimensional cube illustrated in <a href="#filepos2251298">Figure 13.6</a> represents a view of sales with product, location, and time dimensions.</p>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><span class="calibre14"><a id="filepos2251298"></a><span class="calibre14">FIGURE 13.6 Three-dimensional view of sales</span></span></span></p><div class="calibre58"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00503.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre73"><span class="calibre8">SOURCE: Course Technology/Cengage Learning</span></p><div class="calibre13"> </div>
<hr class="calibre10"/><p class="calibre9">Keep in mind that this cube is only a <span class="italic">conceptual</span> representation of multidimensional data; it does not show how the data are physically stored in a data warehouse.</p>
<p class="calibre9">Whatever the underlying database technology, one of the main features of multidimensional analysis is its ability to focus on specific “slices” of the cube. For example, the product manager may be interested in examining the sales of a product while the store manager is interested in examining the sales made by a particular store. In multidimensional terms, the ability to focus on slices of the cube to perform a more detailed analysis is known as <a id="filepos2252372"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2864787">slice and dice</a>. <a href="#filepos2252735">Figure 13.7</a> illustrates the slice-and-dice concept; note that each cut across the cube yields a slice. Intersecting slices produce small cubes that constitute the “dice” part of the slice-and-dice operation.</p>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><span class="calibre14"><a id="filepos2252735"></a><span class="calibre14">FIGURE 13.7 Slice-and-dice view of sales</span></span></span></p><div class="calibre58"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00504.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre73"><span class="calibre8">SOURCE: Course Technology/Cengage Learning</span></p><div class="calibre13"> </div>
<hr class="calibre10"/><p class="calibre9">To slice and dice, it must be possible to identify each slice of the cube. To do so, you use the values of each attribute in a given dimension. For example, to use the location dimension, you might need to define a STORE_ID attribute to focus on a particular store.</p>
<p class="calibre9">Given the requirement for attribute values in a slice-and-dice environment, reexamine <a href="#filepos2249871">Table 13.10</a>. Note that each attribute adds perspective to the sales facts, thus setting the stage for finding new ways to search, classify, and possibly aggregate information. For example, the location dimension adds a geographic perspective of where the sales took place: in which region, state, city, store, and so on. All of the attributes are selected with the objective of providing decision support data to end users so they can study sales by each of the dimension’s attributes.</p>
<p class="calibre9">Time is an especially important dimension; it provides a framework from which sales patterns can be analyzed and possibly predicted. Also, the time dimension plays an important role when the data analyst is interested in studying sales aggregates by quarter, month, week, and so on. Given the importance and universality of the time dimension from a data analysis perspective, many vendors have added automatic time dimension management features to their data-warehousing products.</p>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><span class="calibre14"><a id="filepos2254679"></a><span class="calibre14">FIGURE 13.8 Location attribute hierarchy</span></span></span></p><div class="calibre58"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00505.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre73"><span class="calibre8">SOURCE: Course Technology/Cengage Learning</span></p><div class="calibre13"> </div>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><a id="filepos2255060"></a>13.5.4 A<span><span class="calibre5">TTRIBUTE</span></span> H<span><span class="calibre5">IERARCHIES</span></span></span></p>
<hr class="calibre10"/><p class="calibre9">Attributes within dimensions can be ordered in a well-defined attribute hierarchy. The <a id="filepos2255335"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2731579">attribute hierarchy</a> provides a topdown data organization that is used for two main purposes: aggregation and drill-down/roll-up data analysis. For example,<a href="#filepos2254679">Figure 13.8</a> shows how the location dimension attributes can be organized in a hierarchy by region, state, city, and store.</p>
<p class="calibre9">The attribute hierarchy provides the capability to perform drilldown and roll-up searches in a data warehouse. For example, suppose a data analyst looks at the answers to the following query: How does the 2011 month-to-date sales performance compare to the 2012 month-to-date sales performance? The data analyst spots a sharp sales decline for March 2012, and thus might decide to drill down inside the month of March to see how sales by regions compared to the previous year. By doing that, the analyst can determine whether the low March sales were reflected in all regions or in only a particular region. This type of drill-down operation can even be extended until the data analyst identifies the store that is performing below the norm.</p>
<p class="calibre9">The March sales scenario is possible because the attribute hierarchy allows the data warehouse and BI systems to have a defined path that identifies how data are to be decomposed and aggregated for drill-down and roll-up operations. It is not necessary for all attributes to be part of an attribute hierarchy; some attributes exist merely to provide narrative descriptions of the dimensions. However, keep in mind that the attributes from different dimensions can be grouped to form a hierarchy. For example, after you drill down from city to store, you might want to drill down using the product dimension so the manager can identify slow-selling products in the store. The product dimension can be based on the product group (dairy, meat, and so on) or the product brand (Brand A, Brand B, and so on).</p>
<p class="calibre9"><a href="#filepos2258130">Figure 13.9</a> illustrates a scenario in which the data analyst studies sales facts using the product, time, and location dimensions. In this example, the product dimension is set to “All products,” meaning that the data analyst will see all products on the y-axis. The time dimension (x-axis) is set to “Quarter,” meaning that the data are aggregated by quarters—for example, total sales of products A, B, and C in Q1, Q2, Q3, and Q4. Finally, the location dimension is initially set to “Region,” thus ensuring that each cell contains the total regional sales for a given product in a given quarter.</p>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><span class="calibre14"><a id="filepos2258130"></a><span class="calibre14">FIGURE 13.9 Attribute hierarchies in multidimensional analysis</span></span></span></p><div class="calibre58"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00506.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre73"><span class="calibre8">SOURCE: Course Technology/Cengage Learning</span></p><div class="calibre13"> </div>
<hr class="calibre10"/><p class="calibre9">The simple scenario illustrated in <a href="#filepos2258130">Figure 13.9</a> provides the data analyst with three different information paths. On the product dimension (the y-axis), the data analyst can request to see all products, products grouped by type, or just one product. On the time dimension (the x-axis), the data analyst can request time-variant data at different levels of aggregation: year, quarter, month, or week. Each sales value initially shows the total sales, by region, of each product. When a GUI is used, clicking on the region cell enables the data analyst to drill down to see sales by states within the region. Clicking again on one of the state values yields the sales for each city in the state, and so forth.</p>
<p class="calibre9">As the preceding examples illustrate, attribute hierarchies determine how the data in the data warehouse are extracted and presented. The attribute hierarchy information is stored in the DBMS’s data dictionary and is used by the BI tool to access the data warehouse properly. Once such access is ensured, query tools must be closely integrated with the data warehouse’s metadata, and they must support powerful analytical capabilities.</p>
<p class="calibre69"><span class="calibre8"><a id="filepos2259841"></a>13.5.5 S<span><span class="calibre5">TAR</span></span> S<span><span class="calibre5">CHEMA</span></span> R<span><span class="calibre5">EPRESENTATION</span></span></span></p>
<hr class="calibre10"/><p class="calibre9">Facts and dimensions are normally represented by physical tables in the data warehouse database. The fact table is related to each dimension table in a many-to-one (M:1) relationship. In other words, many fact rows are related to each dimension row. Using the sales example, you can conclude that each product appears many times in the SALES fact table.</p>
<p class="calibre9">Fact and dimension tables are related by foreign keys and are subject to the familiar primary key and foreign key constraints. The primary key on the “1” side, the dimension table, is stored as part of the primary key on the “many” side, the fact table. <span class="italic">Because the fact table is related to many dimension tables, the primary key of the fact table is a composite primary key</span>. <a href="#filepos2261347">Figure 13.10</a> illustrates the relationships among the sales fact table and the product, location, and time dimension tables. To show you how easily the star schema can be expanded, a customer dimension has been added to the mix. Adding the customer dimension merely required including the CUST_ID in the SALES fact table and adding the CUSTOMER table to the database.</p>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><span class="calibre14"><a id="filepos2261347"></a><span class="calibre14">FIGURE 13.10 Star schema for SALES</span></span></span></p><div class="calibre58"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00507.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre73"><span class="calibre8">SOURCE: Course Technology/Cengage Learning</span></p><div class="calibre13"> </div>
<hr class="calibre10"/><p class="calibre9">The composite primary key for the SALES fact table is composed of TIME_ID, LOC_ID, CUST_ID, and PROD_ID. Each record in the SALES fact table is uniquely identified by the combination of values for each of the fact table’s foreign keys. <span class="italic">By default, the fact table’s primary key is always formed by combining the foreign keys pointing to the dimension tables to which they are related</span>. In this case, each sales record represents each product sold to a specific customer, at a specific time, and in a specific location. In this schema, the TIME dimension table represents daily periods, so the SALES fact table represents daily sales aggregates by product and by customer. Because fact tables contain the actual values used in the decision support process, those values are repeated many times in the fact tables. Therefore, the fact tables are always the largest tables in the star schema. Because the dimension tables contain only nonrepetitive information, such as all unique salespersons and all unique products, the dimension tables are always smaller than the fact tables.</p>
<p class="calibre9">In a typical star schema, each dimension record is related to thousands of fact records. For example, “widget” appears only once in the product dimension, but it has thousands of corresponding records in the SALES fact table. This characteristic of the star schema facilitates data retrieval because the data analyst usually looks at the facts through the dimension’s attributes. Therefore, a data warehouse DBMS that is optimized for decision support first searches the smaller dimension tables before accessing the larger fact tables.</p>
<p class="calibre9">Data warehouses usually have many fact tables. Each fact table is designed to answer specific decision support questions. For example, suppose that you develop a new interest in orders while maintaining your original interest in sales. In that scenario, you should maintain an ORDERS fact table and a SALES fact table in the same data warehouse. If orders are considered to be an organization’s key interest, the ORDERS fact table should be the center of a star schema that might have vendor, product, and time dimensions. In that case, an interest in vendors yields a new vendor dimension, represented by a new VENDOR table in the database. The product dimension is represented by the same product table used in the initial sales star schema. However, given the interest in orders as well as sales, the time dimension now requires special attention. If the orders department uses the same time periods as the sales department, time can be represented by the same time table. If different time periods are used, you must create another table, perhaps named ORDER_TIME, to represent the time periods used by the orders department. In <a href="#filepos2264804">Figure 13.11</a>, the orders star schema shares the product, vendor, and time dimensions.</p>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><span class="calibre14"><a id="filepos2264804"></a><span class="calibre14">FIGURE 13.11 Orders star schema</span></span></span></p><div class="calibre58"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00508.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre73"><span class="calibre8">SOURCE: Course Technology/Cengage Learning</span></p><div class="calibre13"> </div>
<hr class="calibre10"/><p class="calibre9">Multiple fact tables can also be created for performance and semantic reasons. The following section explains several performance-enhancing techniques that can be used within the star schema.</p>
<p class="calibre69"><span class="calibre8"><a id="filepos2265437"></a>13.5.6 P<span><span class="calibre5">ERFORMANCE</span></span>-I<span><span class="calibre5">MPROVING</span></span> T<span><span class="calibre5">ECHNIQUES FOR THE</span></span> S<span><span class="calibre5">TAR</span></span> S<span><span class="calibre5">CHEMA</span></span></span></p>
<hr class="calibre10"/><p class="calibre9">Creating a database that provides fast and accurate answers to data analysis queries is the prime objective of data warehouse design. Therefore, performance enhancement might target query speed through the facilitation of SQL code and through better semantic representation of business dimensions. The following four techniques are often used to optimize data warehouse design:</p>
<p class="calibre70">     •    Normalizing dimensional tables</p><div class="calibre3"> </div>
<p class="calibre71">     •    Maintaining multiple fact tables to represent different aggregation levels</p><div class="calibre58"> </div>
<p class="calibre71">     •    Denormalizing fact tables</p><div class="calibre58"> </div>
<p class="calibre72">     •     Partitioning and replicating tables</p>
<p class="calibre83"><span class="calibre5"><span class="calibre14">Normalizing Dimensional Tables</span></span></p>
<p class="calibre53">Dimensional tables are normalized to achieve semantic simplicity and facilitate end-user navigation through the dimensions. For example, if the location dimension table contains transitive dependencies among region, state, and city, you can revise those relationships to the 3NF (third normal form), as shown in <a href="#filepos2267669">Figure 13.12</a>. (If necessary, review the normalization techniques in <a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_018.html#filepos861217">Chapter 6</a>, Normalization of Database Tables.) The star schema shown in <a href="#filepos2267669">Figure 13.12</a> is known as a <a id="filepos2267365"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2865021">snowflake schema</a>, which is a type of star schema in which the dimension tables can have their own dimension tables. The snowflake schema is usually the result of normalizing dimension tables.</p>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><span class="calibre14"><a id="filepos2267669"></a><span class="calibre14">FIGURE 13.12 Normalized dimension tables</span></span></span></p><div class="calibre58"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00509.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre73"><span class="calibre8">SOURCE: Course Technology/Cengage Learning</span></p><div class="calibre13"> </div>
<hr class="calibre10"/><p class="calibre9">By normalizing the dimension tables, you simplify the data-filtering operations related to the dimensions. In this example, the region, state, city, and location contain very few records compared to the SALES fact table. Only the location table is directly related to the SALES fact table.</p>
<p class="calibre48"> </p>
<hr class="calibre10"/><p class="calibre63">N<span><span class="calibre8">OTE</span></span></p>
<hr class="calibre10"/><blockquote class="calibre38"><p class="calibre53">Although using the dimension tables shown in <a href="#filepos2267669">Figure 13.12</a> provides structural simplicity, there is a price to pay for that simplicity. For example, if you want to aggregate the data by region, you must use a fourtable join, thus increasing the complexity of the SQL statements. The star schema in <a href="#filepos2261347">Figure 13.10</a> uses a LOCATION dimension table that greatly facilitates data retrieval by eliminating multiple join operations. This is yet another example of the trade-offs that designers must consider.</p></blockquote>
<hr class="calibre10"/><p class="calibre83"><span class="calibre5"><span class="calibre14">Maintaining Multiple Fact Tables That Represent Different Aggregation Levels</span></span></p>
<p class="calibre53">You can also speed up query operations by creating and maintaining multiple fact tables related to each level of aggregation (region, state, and city) in the location dimension. These aggregate tables are precomputed at the data-loading phase rather than at run time. The purpose of this technique is to save processor cycles at run time, thereby speeding up data analysis. An end-user query tool optimized for decision analysis then properly accesses the summarized fact tables instead of computing the values by accessing a fact table at a lower level of detail. This technique is illustrated in <a href="#filepos2270197">Figure 13.13</a>, which adds aggregate fact tables for region, state, and city to the initial sales example.</p>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><span class="calibre14"><a id="filepos2270197"></a><span class="calibre14">FIGURE 13.13 Multiple fact tables</span></span></span></p><div class="calibre58"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00510.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre73"><span class="calibre8">SOURCE: Course Technology/Cengage Learning</span></p><div class="calibre13"> </div>
<hr class="calibre10"/><p class="calibre9">The data warehouse designer must identify which levels of aggregation to precompute and store in the database. These multiple aggregate fact tables are updated during each load cycle in batch mode. Also, because the objective is to minimize access according to the expected frequency of use and to minimize the processing time required to calculate a given aggregation level at run time, the data warehouse designer must select which aggregation fact tables to create.</p>
<p class="calibre83"><span class="calibre5"><span class="calibre14">Denormalizing Fact Tables</span></span></p>
<p class="calibre53">Denormalizing fact tables improves data access performance and saves data storage space. The latter objective, however, is becoming less of an issue. Data storage costs decrease almost daily, and DBMS limitations on database and table size, record size, and the maximum number of records in a single table have far more negative effects than raw storage space costs.</p>
<p class="calibre9">Denormalization improves performance by using a single record to store data that normally take many records. For example, to compute the total sales for all products in all regions, you might have to access the region sales aggregates and summarize all of the records in this table. If you have 300,000 product sales, you could be summarizing at least 300,000 rows. Although this might not be a taxing operation for a DBMS, a comparison of 10 years’ worth of previous sales begins to bog down the system. In such cases, it is useful to have special aggregate tables that are denormalized. For example, a YEAR_TOTALS table might contain the following fields: YEAR_ID, MONTH_1, MONTH_2 ... MONTH_12, and each year’s total. Such tables can easily be used to serve as a basis for year-to-year comparisons at the top month level, the quarter level, or the year level. Here again, design criteria such as frequency of use and performance requirements are evaluated against the possible overload placed on the DBMS to manage the denormalized relations.</p>
<p class="calibre83"><span class="calibre5"><span class="calibre14">Partitioning and Replicating Tables</span></span></p>
<p class="calibre53">Because table partitioning and replication were covered in detail in <a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_030.html#filepos2024073">Chapter 12</a>, Distributed Database Management Systems, those techniques are discussed here only as they specifically relate to the data warehouse. Table partitioning and replication are particularly important when a BI system is implemented in dispersed geographic areas. <a id="filepos2273250"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2838266">Partitioning</a> splits a table into subsets of rows or columns and places the subsets close to the client computer to improve data access time. <a id="filepos2273425"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2853775">Replication</a> makes a copy of a table or partition and places it in a different location, also to improve access time.</p>
<p class="calibre9">No matter which performance-enhancement scheme is used, time is the most common dimension used in business data analysis. Therefore, it is very common to have one fact table for each level of aggregation defined within the time dimension. In the sales example, you might have five aggregate sales fact tables: daily, weekly, monthly, quarterly, and yearly. These fact tables must have an implicit or explicit periodicity defined. <a id="filepos2274075"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2839226">Periodicity</a>, which is usually expressed as current year only, previous years, or all years, provides information about the time span of the data stored in the table.</p>
<p class="calibre9">At the end of each year, daily sales for the current year are moved to another table that contains previous years’ daily sales only. This table actually contains all sales records from the beginning of operations, with the exception of the current year. The data in the current year and previous years’ tables thus represent the complete sales history of the company. The previous years’ sales table can be replicated at several locations to avoid having to remotely access the historic sales data, which can cause a slow response time. The possible size of this table is enough to intimidate all but the bravest of query optimizers. Here is one case in which denormalization would be of value!</p>
<p class="calibre9">In this section you learned how the star schema design technique allows you to model data optimized for business decision making. BI tools use the data warehouse data as the raw materials for data analytics to generate business knowledge.</p>
<p class="calibre33"> </p>
<hr class="calibre10"/><p class="calibre22"><span class="calibre35"><a id="filepos2275504"></a>13.6 D<span><span class="calibre68">ATA</span></span> A<span><span class="calibre68">NALYTICS</span></span></span></p>
<hr class="calibre10"/><p class="calibre9">Data analytics is a subset of BI functionality that encompasses a wide range of mathematical, statistical, and modeling techniques with the purpose of extracting knowledge from data. Data analytics is used at all levels within the BI framework, including queries and reporting, monitoring and alerting, and data visualization. Hence, data analytics is a “shared” service that is crucial to what BI adds to an organization. Data analytics represents what business managers really want from BI: the ability to extract actionable business insight from current events and foresee future problems or opportunities.</p>
<p class="calibre9"><a id="filepos2276362"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2754830">Data analytics</a> discovers characteristics, relationships, dependencies, or trends in the organization’s data, and then explains the discoveries and predicts future events based on the discoveries. In practice, data analytics is better understood as a continuous spectrum of knowledge acquisition that goes from <span class="italic">discovery</span> to <span class="italic">explanation</span> to <span class="italic">prediction</span>. The outcomes of data analytics then become part of the information framework on which decisions are built. Based on the previous discussion, data analytics tools can be grouped into two separate (but closely related and often overlapping) areas:</p>
<p class="calibre70">     •    <a id="filepos2277093"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2788422">Explanatory analytics</a> focuses on discovering and explaining data characteristics and relationships based on existing data. Explanatory analytics uses statistical tools to formulate hypotheses, test them, and answer the <span class="italic">how</span> and <span class="italic">why</span> of such relationships—for example, how do past sales relate to previous customer promotions?</p><div class="calibre3"> </div>
<p class="calibre72">     •     <a id="filepos2277545"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2842726">Predictive analytics</a> focuses on <span class="italic">predicting future data outcomes</span> with a high degree of accuracy. Predictive analytics uses sophisticated statistical tools to help the end user create advanced models that answer questions about future data occurrences—for example, what would next month’s sales be based on a given customer promotion?</p>
<p class="calibre9">You can think of explanatory analytics as explaining the past and present, while predictive analytics forecasts the future. However, you need to understand that both sciences work together; predictive analytics uses explanatory analytics as a stepping stone to create predictive models.</p>
<p class="calibre9">Data analytics has evolved over the years from simple statistical analysis of business data to dimensional analysis with OLAP tools, and then from data mining that discovers data patterns, relationships, and trends to its current status of predictive analytics. The next sections illustrate the basic characteristics of data mining and predictive analytics.</p>
<p class="calibre69"><span class="calibre8"><a id="filepos2278771"></a>13.6.1 D<span><span class="calibre5">ATA</span></span> M<span><span class="calibre5">INING</span></span></span></p>
<hr class="calibre10"/><p class="calibre9"><a id="filepos2278949"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2760514">Data mining</a> refers to analyzing massive amounts of data to uncover hidden trends, patterns, and relationships; to form computer models to simulate and explain the findings; and then to use such models to support business decision making. In other words, data mining focuses on the discovery and explanation stages of knowledge acquisition.</p>
<p class="calibre9">To put data mining in perspective, look at the pyramid in <a href="#filepos2280051">Figure 13.14</a>, which represents how knowledge is extracted from data. <span class="italic">Data</span> form the pyramid base and represent what most organizations collect in their operational databases. The second level contains <span class="italic">information</span> that represents the purified and processed data. Information forms the basis for decision making and business understanding. <span class="italic">Knowledge</span> is found at the pyramid’s apex, and represents highly distilled information that provides concise, actionable business insight.</p>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><span class="calibre14"><a id="filepos2280051"></a><span class="calibre14">FIGURE 13.14 Extracting knowledge from data</span></span></span></p><div class="calibre58"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00511.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre73"><span class="calibre8">SOURCE: Course Technology/Cengage Learning</span></p><div class="calibre13"> </div>
<hr class="calibre10"/><p class="calibre9">Current-generation data-mining tools contain many design and application variations to fit specific business requirements. Depending on the problem domain, data-mining tools focus on market niches such as banking, insurance, marketing, retailing, finance, and health care. Within a given niche, data-mining tools can use certain algorithms that are implemented in different ways and applied over different data. Despite the lack of precise standards, data mining consists of four general phases:</p>
<p class="calibre70">     •    Data preparation</p><div class="calibre3"> </div>
<p class="calibre71">     •    Data analysis and classification</p><div class="calibre58"> </div>
<p class="calibre71">     •    Knowledge acquisition</p><div class="calibre58"> </div>
<p class="calibre72">     •     Prognosis</p>
<p class="calibre9">In the <span class="italic">data preparation phase</span>, the main data sets to be used by the data-mining operation are identified and cleansed of any data impurities. Because the data in the data warehouse are already integrated and filtered, the data warehouse usually is the target set for data-mining operations.</p>
<p class="calibre9">The <span class="italic">data analysis and classification phase</span> studies the data to identify common data characteristics or patterns. During this phase, the data-mining tool applies specific <a id="filepos2281944"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2727759">algorithms</a> to find:</p>
<p class="calibre70">     •    Data groupings, classifications, clusters, or sequences</p><div class="calibre3"> </div>
<p class="calibre71">     •    Data dependencies, links, or relationships</p><div class="calibre58"> </div>
<p class="calibre72">     •     Data patterns, trends, and deviations</p>
<p class="calibre9">The <span class="italic">knowledge acquisition phase</span> uses the results of the data analysis and classification phase. During the knowledge acquisition phase, the data-mining tool (with possible intervention by the end user) selects the appropriate modeling or knowledge acquisition algorithms. The most common algorithms used in data mining are based on neural networks, decision trees, rules induction, genetic algorithms, classification and regression trees, memory-based reasoning, and nearest neighbor. A data-mining tool may use many of these algorithms in any combination to generate a computer model that reflects the behavior of the target data set.</p>
<p class="calibre9">Although many data-mining tools focus on the knowledge-discovery phase, others continue to the <span class="italic">prognosis phase</span>. In that phase, the data-mining findings are used to predict future behavior and forecast business outcomes. Examples of data-mining findings can be:</p>
<p class="calibre70">     •    Sixty-five percent of customers who did not use a particular credit card in the last six months are 88 percent likely to cancel that account.</p><div class="calibre3"> </div>
<p class="calibre71">     •    Eighty-two percent of customers who bought a 42-inch or larger LCD TV are 90 percent likely to buy an entertainment center within the next four weeks.</p><div class="calibre58"> </div>
<p class="calibre72">     •     If age &lt; 30, income &lt;= 25,000, credit rating &lt; 3, and credit amount &gt; 25,000, then the minimum loan term is 10 years.</p>
<p class="calibre9">The complete set of findings can be represented in a decision tree, a neural network, a forecasting model, or a visual presentation interface that is used to project future events or results. For example, the prognosis phase might project the likely outcome of a new product rollout or a new marketing promotion. <a href="#filepos2284643">Figure 13.15</a> illustrates the different phases of the data-mining process.</p>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><span class="calibre14"><a id="filepos2284643"></a><span class="calibre14">FIGURE 13.15 Data–mining phases</span></span></span></p><div class="calibre58"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00512.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre73"><span class="calibre8">SOURCE: Course Technology/Cengage Learning</span></p><div class="calibre13"> </div>
<hr class="calibre10"/><p class="calibre9">Because of the nature of the data-mining process, some findings might fall outside the boundaries of what business managers expect. For example, a data-mining tool might find a close relationship between a customer’s favorite brand of soda and the brand of tires on the customer’s car. Clearly, that relationship might not be held in high regard among sales managers. (In regression analysis, those relationships are commonly described by the label “idiot correlation.”)</p>
<p class="calibre9">Fortunately, data mining usually yields more meaningful results. In fact, data mining has proven helpful in finding practical relationships among data that help define customer buying patterns, improve product development and acceptance, reduce healthcare fraud, analyze stock markets, and so on.</p>
<p class="calibre9">Data mining can be run in two modes:</p>
<p class="calibre70">     •    <span class="italic">Guided</span>. The end user guides the data-mining tool step by step to explore and explain known patterns or relationships. In this mode, the end user decides what techniques to apply to the data.</p><div class="calibre3"> </div>
<p class="calibre72">     •     <span class="italic">Automated</span>. In this mode, the end user sets up the data-mining tool to run automatically and uncover hidden patterns, trends, and relationships. The data-mining tool applies multiple techniques to find significant relationships.</p>
<p class="calibre9">As you learned in this section, data-mining methodologies focus on discovering and extracting information that describes and explains the data; for example, an explanatory model could create a customer profile that describes a given customer group. However, data mining can also be used as the basis to create advanced predictive data models. For example, a predictive model could be used to predict future customer behavior, such as a customer response to a target marketing campaign. The next section explains the use of predictive analytics in more detail.</p>
<p class="calibre69"><span class="calibre8"><a id="filepos2287249"></a>13.6.2 P<span><span class="calibre5">REDICTIVE</span></span> A<span><span class="calibre5">NALYTICS</span></span></span></p>
<hr class="calibre10"/><p class="calibre9">Although the term <span class="italic">predictive analytics</span> is used by many BI vendors to indicate many different levels of functionality, the promise of predictive analytics is very attractive for businesses looking for ways to improve their bottom line. Therefore, predictive analytics is receiving a lot of marketing buzz; vendors and businesses are dedicating extensive resources to this BI area. Predictive analytics refers to the use of advanced mathematical, statistical, and modeling tools to predict future business outcomes with high degrees of accuracy.</p>
<p class="calibre9">What is the difference between data mining and predictive analytics? As you learned earlier, data mining also has predictive capabilities. In fact, data mining and predictive analytics use similar and overlapping sets of tools, but with a slightly different focus. Data mining focuses on answering the “how” and “what” of <span class="italic">past</span> data, while predictive analytics focuses on creating actionable models to predict <span class="italic">future</span> behaviors and events. In some ways, you can think of predictive analytics as the next logical step after data mining; once you understand your data, you can use the data to predict future behaviors. In fact, most BI vendors are dropping the term <span class="italic">data mining</span> and replacing it with the more alluring term <span class="italic">predictive analytics</span>.</p>
<p class="calibre9">The origins of predictive analytics can be traced back to the banking and credit card industries. The need to profile customers and predict customer buying patterns in these industries was a critical driving force for the evolution of many modeling methodologies used in BI data analytics today. For example, based on your demographic information and purchasing history, a credit card company can use data-mining models to determine what credit limit to offer, what offers you are more likely to accept, and when to send those offers.</p>
<p class="calibre9">Predictive analytics received a big stimulus with the advent of social media. Companies turned to data mining and predictive analytics as a way to harvest the mountains of data stored on social media sites. Google was one of the first companies that offered targeted ads as a way to increase and personalize search experiences. Similar initiatives were used by all types of organizations to increase customer loyalty and drive up sales. Take the example of the airline and credit card industries and their frequent flyer and affinity card programs. Nowadays, many organizations use predictive analytics to profile customers in an attempt to get and keep the right ones, which in turn will increase loyalty and sales.<sup class="calibre56"><a href="#filepos2374364">4</a></sup></p>
<p class="calibre9">Predictive analytics employs mathematical and statistical algorithms, neural networks, artificial intelligence, and other advanced modeling tools to create actionable predictive models based on available data. The algorithms used to build the predictive model are specific to certain types of problems and work with certain types of data. Therefore, it is important that the end user, who typically is trained in statistics and understands business, applies the proper algorithms to the problem in hand. However, thanks to constant technology advances, modern BI tools automatically apply multiple algorithms to find the optimum model.</p>
<p class="calibre9">Most predictive analytics models are used in areas such as customer relationships, customer service, customer retention, fraud detection, targeted marketing, and optimized pricing. Predictive analytics can add value to an organization in many different ways; for example, it can help optimize existing processes, identify hidden problems, and anticipate future problems or opportunities. However, predictive analytics is not the “secret sauce” to fix all business problems. Managers should carefully monitor and evaluate the value of predictive analytics models to determine their return on investment.</p>
<p class="calibre9">So far, you have learned about data warehouses and star schemas to model and store decision support data, and data analytics to extract knowledge from the data. A BI system uses all the previously mentioned components to provide decision support to all organizational users. In the next section you will learn about a widely used BI style known as online analytical processing.</p>
<p class="calibre33"> </p>
<hr class="calibre10"/><p class="calibre22"><span class="calibre35"><a id="filepos2292235"></a>13.7 O<span><span class="calibre68">NLINE</span></span> A<span><span class="calibre68">NALYTICAL</span></span> P<span><span class="calibre68">ROCESSING</span></span></span></p>
<hr class="calibre10"/><p class="calibre9"><a id="filepos2292463"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2832564">Online analytical processing (OLAP)</a> is a BI style whose systems share three main characteristics:</p>
<p class="calibre70">     •    Multidimensional data analysis techniques</p><div class="calibre3"> </div>
<p class="calibre71">     •    Advanced database support</p><div class="calibre58"> </div>
<p class="calibre72">     •     Easy-to-use end-user interfaces</p>
<p class="calibre9">This section examines each characteristic.</p>
<p class="calibre69"><span class="calibre8"><a id="filepos2293115"></a>13.7.1 M<span><span class="calibre5">ULTIDIMENSIONAL</span></span> D<span><span class="calibre5">ATA</span></span> A<span><span class="calibre5">NALYSIS</span></span> T<span><span class="calibre5">ECHNIQUES</span></span></span></p>
<hr class="calibre10"/><p class="calibre9">The most distinctive characteristic of modern OLAP tools is their capacity for multidimensional analysis, in which data are processed and viewed as part of a multidimensional structure. This type of data analysis is particularly attractive to business decision makers because they tend to view business data as being related to other business data.</p>
<p class="calibre9">To better understand this view, you can examine how a business data analyst might investigate sales figures. In this case, the analyst is probably interested in the sales figures as they relate to other business variables such as customers and time. In other words, customers and time are viewed as different dimensions of sales. <a href="#filepos2294363">Figure 13.16</a> illustrates how the operational (one-dimensional) view differs from the multidimensional view of sales.</p>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><span class="calibre14"><a id="filepos2294363"></a><span class="calibre14">FIGURE 13.16 Operational vs. multidimensional view of sales</span></span></span></p><div class="calibre58"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00513.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre73"><span class="calibre8">SOURCE: Course Technology/Cengage Learning</span></p><div class="calibre13"> </div>
<hr class="calibre10"/><p class="calibre9">Note in <a href="#filepos2294363">Figure 13.16</a> that the operational (tabular) view of sales data is not well suited to decision support because the relationship between INVOICE and LINE does not provide a business perspective of the sales data. On the other hand, the end user’s view of sales data <span class="italic">from a business perspective</span> is more closely represented by the multidimensional view of sales than by the tabular view of separate tables. Note also that the multidimensional view allows end users to consolidate or aggregate data at different levels: total sales figures by customers and by date. Finally, the multidimensional view of data allows a business data analyst to easily switch business perspectives (dimensions) from sales by customer to sales by division, by region, and so on.</p>
<p class="calibre9">Multidimensional data analysis techniques are augmented by the following functions:</p>
<p class="calibre70">     •    <span class="italic">Advanced data presentation functions</span>. These functions include 3D graphics, pivot tables, crosstabs, data rotation, and three-dimensional cubes. Such tools are compatible with desktop spreadsheets, statistical packages, and query and report packages.</p><div class="calibre3"> </div>
<p class="calibre71">     •    <span class="italic">Advanced data aggregation, consolidation, and classification functions</span>. These allow the data analyst to create multiple data aggregation levels, slice and dice data (see <a href="#filepos2249092">Section 13.5.3</a>), and drill down and roll up data across different dimensions and aggregation levels. For example, aggregating data by week, month, quarter, and year allows the data analyst to drill down and roll up across time dimensions.</p><div class="calibre58"> </div>
<p class="calibre71">     •    <span class="italic">Advanced computational functions</span>. These include business-oriented variables such as market share, period comparisons, sales margins, product margins, and percentage changes; financial and accounting ratios, including profitability, overhead, cost allocations, and returns; and statistical and forecasting functions. These functions are provided automatically, so the end user does not need to redefine the components each time they are accessed.</p><div class="calibre58"> </div>
<p class="calibre72">     •     <span class="italic">Advanced data-modeling functions</span>. These provide support for what-if scenarios, variable assessment, contributions to outcome, linear programming, and predictive modeling tools. Predictive modeling allows the system to build advanced statistical models to predict future values (business outcomes) with a high percentage of accuracy.</p>
<p class="calibre69"><span class="calibre8"><a id="filepos2297592"></a>13.7.2 A<span><span class="calibre5">DVANCED</span></span> D<span><span class="calibre5">ATABASE</span></span> S<span><span class="calibre5">UPPORT</span></span></span></p>
<hr class="calibre10"/><p class="calibre9">To deliver efficient decision support, OLAP tools must have the following advanced data access features:</p>
<p class="calibre70">     •    Access to many different kinds of DBMSs, flat files, and internal and external data sources</p><div class="calibre3"> </div>
<p class="calibre71">     •    Access to aggregated data warehouse data as well as to the detail data found in operational databases</p><div class="calibre58"> </div>
<p class="calibre71">     •    Advanced data navigation features such as drill-down and roll-up</p><div class="calibre58"> </div>
<p class="calibre71">     •    Rapid and consistent query response times</p><div class="calibre58"> </div>
<p class="calibre71">     •    The ability to map end-user requests, expressed in either business or model terms, to the appropriate data source and then to the proper data access language (usually SQL). The query code must be optimized to match the data source, regardless of whether the source is operational or data warehouse data.</p><div class="calibre58"> </div>
<p class="calibre72">     •     Support for very large databases. As explained earlier, the data warehouse could easily and quickly grow to multiple terabytes in size.</p>
<p class="calibre9">To provide a seamless interface, OLAP tools map the data elements from the data warehouse and the operational database to their own data dictionaries. These metadata are used to translate end-user data analysis requests into the proper (optimized) query codes, which are then directed to the appropriate data sources.</p>
<p class="calibre69"><span class="calibre8"><a id="filepos2299597"></a>13.7.3 E<span><span class="calibre5">ASY-TO</span></span>-U<span><span class="calibre5">SE</span></span> E<span><span class="calibre5">ND</span></span>-U<span><span class="calibre5">SER</span></span> I<span><span class="calibre5">NTERFACES</span></span></span></p>
<hr class="calibre10"/><p class="calibre9">The end-user analytical interface is one of the most critical OLAP components. When properly implemented, an analytical interface permits the user to navigate the data in a way that simplifies and accelerates decision making or data analysis.</p>
<p class="calibre9">Advanced OLAP features become more useful when access to them is kept simple. OLAP tool vendors learned this lesson early and have equipped their sophisticated data extraction and analysis tools with easy-to-use graphical interfaces. Many of the interface features are “borrowed” from previous generations of data analysis tools that are already familiar to end users.</p>
<p class="calibre9">Because many analysis and presentation functions are common to desktop spreadsheet packages, most OLAP vendors have closely integrated their systems with spreadsheets such as Microsoft Excel. Using the features available in graphical end-user interfaces, OLAP simply becomes another option within the spreadsheet menu bar, as shown in <a href="#filepos2301363">Figure 13.17</a>. This seamless integration is an advantage for OLAP systems and spreadsheet vendors because end users gain access to advanced data analysis features by using familiar programs and interfaces. Therefore, additional training and development costs are minimized.</p>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><span class="calibre14"><a id="filepos2301363"></a><span class="calibre14">FIGURE 13.17 Integration of OLAP with a spreadsheet program</span></span></span></p><div class="calibre58"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00514.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre73"><span class="calibre8">SOURCE: Course Technology/Cengage Learning</span></p><div class="calibre13"> </div>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><a id="filepos2301763"></a>13.7.4 O<span><span class="calibre5">LAP</span></span> A<span><span class="calibre5">RCHITECTURE</span></span></span></p>
<hr class="calibre10"/><p class="calibre9">The OLAP architecture is designed to meet ease-of-use requirements while keeping the system flexible. An OLAP system has three main architectural components:</p>
<p class="calibre70">     •    Graphical user interface (GUI)</p><div class="calibre3"> </div>
<p class="calibre71">     •    Analytical processing logic</p><div class="calibre58"> </div>
<p class="calibre72">     •     Data-processing logic</p>
<p class="calibre9">These three components can exist on the same computer or be distributed among several computers. <a href="#filepos2302754">Figure 13.18</a> illustrates OLAP’s architectural components.</p>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><span class="calibre14"><a id="filepos2302754"></a><span class="calibre14">FIGURE 13.18 OLAP architecture</span></span></span></p><div class="calibre58"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00515.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre73"><span class="calibre8">Credit: Oleksiy Mark / <a href="http://Shutterstock.com">Shutterstock.com</a></span></p><div class="calibre13"> </div>
<p class="calibre22"><span class="calibre8">SOURCE: Course Technology/Cengage Learning</span></p><div class="calibre13"> </div>
<hr class="calibre10"/><p class="calibre9">As <a href="#filepos2302754">Figure 13.18</a> illustrates, OLAP systems are designed to use both operational and data warehouse data. The figure shows the OLAP system components on a single computer, but this single-user scenario is only one of many. In fact, one problem with the installation shown here is that each data analyst must have a powerful computer to store the OLAP system and perform all data processing locally.</p>
<p class="calibre9">A more common and practical architecture is one in which the OLAP GUI runs on client workstations while the OLAP data-processing logic (or OLAP “server”) runs on a shared server computer. The OLAP analytical processing logic could be located on a client workstation, the OLAP server, or be split between the two sides. In any case, the OLAP server component acts as an intermediary between the OLAP GUI and the data warehouse. This middle layer accepts and handles the data-processing requests generated by the many end-user OLAP workstations. This flexible architecture allows for many different OLAP configurations. <a href="#filepos2304579">Figure 13.19</a> illustrates an OLAP server with local miniature data marts.</p>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><span class="calibre14"><a id="filepos2304579"></a><span class="calibre14">FIGURE 13.19 OLAP server with local miniature data marts</span></span></span></p><div class="calibre58"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00516.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre73"><span class="calibre8">SOURCE: Course Technology/Cengage Learning</span></p><div class="calibre13"> </div>
<hr class="calibre10"/><p class="calibre9">As illustrated in <a href="#filepos2304579">Figure 13.19</a>, the OLAP system could merge the data warehouse and data mart approaches by storing extracts of the data warehouse at end-user workstations. The objective is to increase the speed of data access and data visualization (the graphic representations of data trends and characteristics). The logic behind this approach is the assumption that most end users usually work with fairly small, stable data warehouse subsets. For example, a sales analyst is most likely to work with sales data, whereas a customer representative is likely to work with customer data.</p>
<p class="calibre9">Whatever the arrangement of the OLAP components, one thing is certain: multidimensional data must be used. But how are multidimensional data best stored and managed? OLAP proponents are sharply divided. Some favor the use of relational databases to store multidimensional data; others argue that specialized multidimensional databases are superior. The basic characteristics of each approach are examined next.</p>
<p class="calibre69"><span class="calibre8"><a id="filepos2306140"></a>13.7.5 R<span><span class="calibre5">ELATIONAL</span></span> OLAP</span></p>
<hr class="calibre10"/><p class="calibre9"><a id="filepos2306287"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2851014">Relational online analytical processing (ROLAP)</a> provides OLAP functionality by using relational databases and familiar relational query tools to store and analyze multidimensional data. This approach builds on existing relational technologies and represents a natural extension to companies that already use relational database management systems within their organizations. ROLAP adds the following extensions to traditional RDBMS technology:</p>
<p class="calibre70">     •    Multidimensional data schema support within the RDBMS</p><div class="calibre3"> </div>
<p class="calibre71">     •    Data access language and query performance optimized for multidimensional data</p><div class="calibre58"> </div>
<p class="calibre72">     •     Support for very large databases (VLDBs)</p>
<p class="calibre83"><span class="calibre5"><span class="calibre14">Multidimensional Data Schema Support within the RDBMS</span></span></p>
<p class="calibre53">Relational technology uses normalized tables to store data. The reliance on normalization as the design methodology for relational databases is seen as a stumbling block to its use in OLAP systems. Normalization divides business entities into smaller pieces to produce the normalized tables. For example, sales data components might be stored in four or five different tables. The reason for using normalized tables is to reduce redundancies, thereby eliminating data anomalies, and to facilitate data updates. Unfortunately, for decision support purposes, it is easier to understand data when they are seen with respect to other data. (See the example in <a href="#filepos2294363">Figure 13.16</a>.) Given that view of the data environment, this book has emphasized that decision support data tend to be non-normalized, duplicated, and preaggregated. Those characteristics seem to preclude the use of standard relational design techniques and RDBMSs as the foundation for multidimensional data.</p>
<p class="calibre9">Fortunately for companies heavily invested in relational technology, ROLAP uses a special design technique that enables RDBMS technology to support multidimensional data representations. This special design technique is known as a star schema, which is covered in detail in <a href="#filepos2245746">Section 13.5</a>.</p>
<p class="calibre9">The star schema is designed to optimize data query operations rather than data update operations. Naturally, changing the data design foundation means that the tools used to access such data will have to change. End users who are familiar with traditional relational query tools will discover that those tools do not work efficiently with the star schema. However, ROLAP saves the day by adding support for the star schema when familiar query tools are used. ROLAP provides advanced data analysis functions and improves query optimization and data visualization methods.</p>
<p class="calibre83"><span class="calibre5"><span class="calibre14">Data Access Language and Query Performance Optimized for Multidimensional Data</span></span></p>
<p class="calibre53">Another criticism of relational databases is that SQL is not suited for performing advanced data analysis. Most decision support data requests require the use of multiple-pass SQL queries or multiple nested SQL statements. To answer this criticism, ROLAP extends SQL so that it can differentiate between access requirements for data warehouse data (based on the star schema) and operational data (normalized tables). A ROLAP system therefore can generate the SQL code required to access the star schema data.</p>
<p class="calibre9">Query performance is also improved because the query optimizer is modified to identify the SQL code’s intended query targets. For example, if the query target is the data warehouse, the optimizer passes the requests to the data warehouse. However, if the end user performs drill-down queries against operational data, the query optimizer identifies that operation and properly optimizes the SQL requests before passing them to the operational DBMS.</p>
<p class="calibre9">Another source of improved query performance is the use of advanced indexing techniques such as bitmapped indexes within relational databases. As the name suggests, a bitmapped index is based on 0 and 1 bits to represent a given condition. For example, if the REGION attribute in <a href="#filepos2213337">Figure 13.3</a> has only four outcomes—North, South, East, and West—those outcomes may be represented as shown in <a href="#filepos2311629">Table 13.11</a>. Only the first 10 rows from <a href="#filepos2213337">Figure 13.3</a> are represented in the table. The “1” represents “bit on,” and the “0” represents “bit off.” For example, to represent a row with a REGION attribute = “East,” only the “East” bit would be on. Note that each row must be represented in the index table.</p>
<p class="calibre48"> </p>
<hr class="calibre10"/><p class="calibre63"><span class="calibre8"><span class="calibre14"><a id="filepos2311629"></a><span class="calibre14">TABE 13.11 Bitmap Representation of Region Values</span></span></span></p><div class="calibre64"> </div>
<hr class="calibre10"/><div class="calibre58"> </div><table class="calibre59"><div class="calibre5">
<thead class="calibre77"><tr class="calibre61"><td class="calibre62"><p class="calibre63">NORTH</p></td><td class="calibre62"><p class="calibre63">SOUTH</p></td><td class="calibre62"><p class="calibre63">EAST</p></td><td class="calibre62"><p class="calibre63">WEST</p></td></tr></thead><tbody class="calibre60"><tr class="calibre61"><td class="calibre62"><p class="calibre63">0</p></td><td class="calibre62"><p class="calibre63">0</p></td><td class="calibre62"><p class="calibre63">1</p></td><td class="calibre62"><p class="calibre63">0</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">0</p></td><td class="calibre62"><p class="calibre63">0</p></td><td class="calibre62"><p class="calibre63">1</p></td><td class="calibre62"><p class="calibre63">0</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">1</p></td><td class="calibre62"><p class="calibre63">0</p></td><td class="calibre62"><p class="calibre63">0</p></td><td class="calibre62"><p class="calibre63">0</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">1</p></td><td class="calibre62"><p class="calibre63">0</p></td><td class="calibre62"><p class="calibre63">0</p></td><td class="calibre62"><p class="calibre63">0</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">1</p></td><td class="calibre62"><p class="calibre63">0</p></td><td class="calibre62"><p class="calibre63">0</p></td><td class="calibre62"><p class="calibre63">0</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">0</p></td><td class="calibre62"><p class="calibre63">1</p></td><td class="calibre62"><p class="calibre63">0</p></td><td class="calibre62"><p class="calibre63">0</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">0</p></td><td class="calibre62"><p class="calibre63">1</p></td><td class="calibre62"><p class="calibre63">0</p></td><td class="calibre62"><p class="calibre63">0</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">0</p></td><td class="calibre62"><p class="calibre63">1</p></td><td class="calibre62"><p class="calibre63">0</p></td><td class="calibre62"><p class="calibre63">0</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">0</p></td><td class="calibre62"><p class="calibre63">0</p></td><td class="calibre62"><p class="calibre63">0</p></td><td class="calibre62"><p class="calibre63">1</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">0</p></td><td class="calibre62"><p class="calibre63">0</p></td><td class="calibre62"><p class="calibre63">0</p></td><td class="calibre62"><p class="calibre63">1</p></td></tr></tbody></div></table><div class="calibre64"> </div>
<hr class="calibre10"/><p class="calibre9">Note that the index in <a href="#filepos2311629">Table 13.11</a> takes a minimal amount of space. Therefore, bitmapped indexes are more efficient at handling large amounts of data than the indexes typically found in many relational databases. However, keep in mind that bitmapped indexes are primarily used when the number of possible values for an attribute is fairly small. For example, REGION has only four outcomes in this example. Marital status—married, single, widowed, or divorced—would be another good bitmapped index candidate, as would gender—M or F.</p>
<p class="calibre83"><span class="calibre5"><span class="calibre14">Support for Very Large Databases</span></span></p>
<p class="calibre53">Recall that support for VLDBs is a requirement for decision support databases. Therefore, when the relational database is used in a decision support role, it also must be able to store very large amounts of data. Both the storage capability and the process of loading data into the database are crucial. Therefore, the RDBMS must have the proper tools to import, integrate, and populate the data warehouse with data. Decision support data are normally loaded in bulk (batch) mode from the operational data. However, batch operations require that both the source and the destination databases be reserved (locked). The speed of the data-loading operations is important, especially when you realize that most operational systems run 24 hours a day, 7 days a week. Therefore, the window of opportunity for maintenance and batch loading is open only briefly, typically during slack periods.</p>
<p class="calibre9">Clearly, ROLAP is a logical choice for companies that already use relational databases for their operational data. Given the size of the relational database market, it is hardly surprising that most current RDBMS vendors have extended their products to support data warehouses and OLAP capabilities.</p>
<p class="calibre69"><span class="calibre8"><a id="filepos2316820"></a>13 .7.6 M<span><span class="calibre5">ULTIDIMENSIONAL</span></span> OLAP</span></p>
<hr class="calibre10"/><p class="calibre9"><a id="filepos2316974"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2824923">Multidimensional online analytical processing (MOLAP)</a> extends OLAP functionality to <a id="filepos2317092"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2824618">multidimensional database management systems (MDBMSs)</a>. An MDBMS uses proprietary techniques to store data in matrixlike <span class="italic">n</span>-dimensional arrays. MOLAP’s premise is that multidimensional databases are best suited to manage, store, and analyze multidimensional data. Most of the proprietary techniques used in MDBMSs are derived from engineering fields such as computer-aided design/computer-aided manufacturing (CAD/CAM) and geographic information systems (GIS). MOLAP tools store data using multidimensional arrays, row stores, or column stores. (If necessary, review the NoSQL data model in <a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_012.html#filepos268583">Chapter 2</a>, Data Models.)</p>
<p class="calibre9">Conceptually, MDBMS end users visualize the stored data as a three-dimensional cube known as a <a id="filepos2317938"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2755700">data cube</a>. The location of each data value in the data cube is a function of the x-, y-, and z-axes in a three-dimensional space. The three axes represent the dimensions of the data value. The data cubes can grow to <span class="italic">n</span> number of dimensions, thus becoming <span class="italic">hypercubes</span>. Data cubes are created by extracting data from the operational databases or from the data warehouse. One important characteristic of data cubes is that they are static; that is, they are not subject to change and must be created before they can be used. Data cubes cannot be created by ad hoc queries. Instead, you query precreated cubes with defined axes; for example, a cube for sales will have the product, location, and time dimensions, and you can query only those dimensions. Therefore, the data cube creation process is critical and requires in-depth front-end design work. This design work may be well justified because MOLAP databases are known to be much faster than their ROLAP counterparts, especially when dealing with large data sets. To speed data access, data cubes are normally held in memory in the <a id="filepos2319069"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2752410">cube cache</a>. (A data cube is only a window to a predefined subset of data in the database. A data cube and a database are not the same thing.) Because MOLAP also benefits from a client/server infrastructure, the cube cache can be located at the MOLAP server, the MOLAP client, or both.</p>
<p class="calibre9">Because the data cube is predefined with a set number of dimensions, the addition of a new dimension requires that the entire data cube be re-created, which is time-consuming. Therefore, when data cubes are created too often, the MDBMS loses some of its speed advantage over the relational database. In addition, the MDBMS uses proprietary data storage techniques that in turn require proprietary data access methods using a multidimensional query language (review the NoSQL model in <a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_012.html#filepos268583">Chapter 2</a>).</p>
<p class="calibre9">Multidimensional data analysis is also affected by how the database system handles sparsity. <a id="filepos2320142"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2866243">Sparsity</a> measures the density of the data held in the data cube; it is computed by dividing the total number of actual values in the cube by its total number of cells. Because the data cube’s dimensions are predefined, not all cells are populated. In other words, some cells are empty. Returning to the sales example, many products might not be sold during a given time period in a given location. In fact, you will often find that less than 50 percent of the data cube’s cells are populated. In any case, multidimensional databases must handle sparsity effectively to reduce processing overhead and resource requirements.</p>
<p class="calibre69"><span class="calibre8"><a id="filepos2320868"></a>13.7.7 R<span><span class="calibre5">ELATIONAL VS.</span></span> M<span><span class="calibre5">ULTIDIMENSIONAL</span></span> OLAP</span></p>
<hr class="calibre10"/><p class="calibre9"><a href="#filepos2321703">Table 13.12</a> summarizes some pros and cons of ROLAP and MOLAP. Keep in mind that the selection of one or the other often depends on the evaluator’s vantage point. For example, a proper evaluation of OLAP must include price, supported hardware platforms, compatibility with the existing DBMS, programming requirements, performance, and availability of administrative tools. The summary in <a href="#filepos2321703">Table 13.12</a> provides a useful starting point for comparison.</p>
<p class="calibre48"> </p>
<hr class="calibre10"/><p class="calibre63"><span class="calibre8"><span class="calibre14"><a id="filepos2321703"></a><span class="calibre14">TABLE 13.12 Relational vs. Multidimensional OLAP</span></span></span></p><div class="calibre64"> </div>
<hr class="calibre10"/><div class="calibre58"> </div><table class="calibre59"><div class="calibre5">
<tr class="calibre61"><td class="calibre62"><p class="calibre63"><span class="calibre14">CHARACTERISTIC</span></p></td><td class="calibre62"><p class="calibre63"><span class="calibre14">ROLAP</span></p></td><td class="calibre62"><p class="calibre63"><span class="calibre14">MOLAP</span></p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">Schema</p></td><td class="calibre62"><p class="calibre63">Uses star schema</p><p class="calibre63">Additional dimensions can be added dynamically</p></td><td class="calibre62"><p class="calibre63">Uses data cubes</p><p class="calibre63">Multidimensional arrays, row stores, column stores</p><p class="calibre63">Additional dimensions require re-creation of the data cube</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">Database size</p></td><td class="calibre62"><p class="calibre63">Medium to large</p></td><td class="calibre62"><p class="calibre63">Large</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">Architecture</p></td><td class="calibre62"><p class="calibre63">Client/server</p><p class="calibre63">Standards-based</p></td><td class="calibre62"><p class="calibre63">Client/server</p><p class="calibre63">Open or proprietary, depending on vendor</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">Access</p></td><td class="calibre62"><p class="calibre63">Supports ad hoc requests</p><p class="calibre63">Unlimited dimensions</p></td><td class="calibre62"><p class="calibre63">Limited to predefined dimensions</p><p class="calibre63">Proprietary access languages</p></td></tr><tr class="calibre61"><td class="calibre62"><p class="calibre63">Speed</p></td><td class="calibre62"><p class="calibre63">Good with small data sets; average for medium-sized to large data sets</p></td><td class="calibre62"><p class="calibre63">Faster for large data sets with predefined dimensions</p></td></tr></div></table><div class="calibre64"> </div>
<hr class="calibre10"/><p class="calibre9">ROLAP and MOLAP vendors are working to integrate their respective solutions within a unified decision support framework. Many OLAP products can handle tabular and multidimensional data with the same ease. For example, if you use Excel OLAP functionality, as shown earlier in <a href="#filepos2301363">Figure 13.17</a>, you can access relational OLAP data in a SQL server as well as cube (multidimensional) data in the local computer. In the meantime, relational databases have successfully extended SQL to support many OLAP tools.</p>
<p class="calibre33"> </p>
<hr class="calibre10"/><p class="calibre22"><span class="calibre35"><a id="filepos2324748"></a>13.8 SQL E<span><span class="calibre68">XTENSIONS FOR</span></span> O<span><span class="calibre68">LAP</span></span></span></p>
<hr class="calibre10"/><p class="calibre9">The proliferation of OLAP tools has fostered the development of SQL extensions to support multidimensional data analysis. Most SQL innovations are the result of vendor-centric product enhancements. However, many of the innovations have made their way into standard SQL. This section introduces some of the new SQL extensions that have been created to support OLAP-type data manipulations.</p>
<p class="calibre9">The SaleCo snowflake schema shown in <a href="#filepos2326001">Figure 13.20</a> demonstrates the use of the SQL extensions. Note that this snowflake schema has a central DWSALESFACT fact table and three dimension tables: DWCUSTOMER, DWPRODUCT, and DWTIME. The central fact table represents daily sales by product and customer. However, as you examine the schema shown in <a href="#filepos2326001">Figure 13.20</a>, you will see that the DWCUSTOMER and DWPRODUCT dimension tables have their own dimension tables: DWREGION and DWVENDOR.</p>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><span class="calibre14"><a id="filepos2326001"></a><span class="calibre14">FIGURE 13.20 SaleCo snowflake schema</span></span></span></p><div class="calibre58"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00517.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre73"><span class="calibre8">SOURCE: Course Technology/Cengage Learning</span></p><div class="calibre13"> </div>
<hr class="calibre10"/><p class="calibre9">Keep in mind that a database is at the core of all data warehouses. Therefore, all SQL commands (such as CREATE, INSERT, UPDATE, DELETE, and SELECT) will work in the data warehouse as expected. However, most queries you run in a data warehouse tend to include a lot of data groupings and aggregations over multiple columns. Therefore, this section introduces two extensions to the GROUP BY clause that are particularly useful: ROLLUP and CUBE. In addition, you will learn about using materialized views to store preaggregated rows in the database.</p>
<hr class="calibre10"/><p class="calibre63"><span class="calibre35"><img alt="img" src="images/00023.jpg" class="calibre7"/> O<span><span class="calibre68">NLINE</span></span> C<span><span class="calibre68">ONTENT</span></span></span></p>
<p class="calibre9">The script files used to populate the database and run the SQL commands are available at <a href="http://www.cengagebrain.com"><span class="italic">www.cengagebrain.com</span></a>.</p>
<hr class="calibre10"/><hr class="calibre10"/><p class="calibre63">N<span><span class="calibre8">OTE</span></span></p>
<hr class="calibre10"/><blockquote class="calibre38"><p class="calibre53">This section uses the Oracle RDBMS to demonstrate the use of SQL extensions to support OLAP functionality. If you use a different DBMS, consult the documentation to verify whether the vendor supports similar functionality and what the proper syntax is for your DBMS.</p></blockquote>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><a id="filepos2327911"></a>13.8.1 T<span><span class="calibre5">HE</span></span> ROLLUP E<span><span class="calibre5">XTENSION</span></span></span></p>
<hr class="calibre10"/><p class="calibre9">The ROLLUP extension is used with the GROUP BY clause to generate aggregates by different dimensions. As you know, the GROUP BY clause will generate only one aggregate for each new value combination of attributes listed in the GROUP BY clause. The ROLLUP extension goes one step further; it enables you to get a subtotal for each column listed except for the last one, which gets a grand total instead. The syntax of the GROUP BY ROLLUP command sequence is as follows:</p>
<p class="calibre9">SELECT column1 [, column2, ...], aggregate_function(expression)</p>
<p class="calibre9">FROM table1 [, table2, …]</p>
<p class="calibre9">[WHERE condition]</p>
<p class="calibre9">GROUP BY ROLLUP (column1 [, column2, ...])</p>
<p class="calibre9">[HAVING condition]</p>
<p class="calibre9">[ORDER BY column1 [, column2, …]]</p>
<p class="calibre9">The order of the column list within GROUP BY ROLLUP is very important. The last column in the list will generate a grand total, and all other columns will generate subtotals. For example, <a href="#filepos2329643">Figure 13.21</a> shows the use of the ROLLUP extension to generate subtotals by vendor and product.</p>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><span class="calibre14"><a id="filepos2329643"></a><span class="calibre14">FIGURE 13.21 ROLLUP extension</span></span></span></p><div class="calibre58"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00518.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre73"><span class="calibre8">SOURCE: Course Technology/Cengage Learning</span></p><div class="calibre13"> </div>
<hr class="calibre10"/><p class="calibre9"><a href="#filepos2329643">Figure 13.21</a> shows the subtotals by vendor code and a grand total for all product codes. Contrast that with the normal GROUP BY clause that generates only the subtotals for each vendor and product combination. The ROLLUP extension is particularly useful when you want to obtain multiple nested subtotals for a dimension hierarchy. For example, within a location hierarchy, you can use ROLLUP to generate subtotals by region, state, city, and store.</p>
<p class="calibre69"><span class="calibre8"><a id="filepos2330558"></a>13.8.2 T<span><span class="calibre5">HE</span></span> CUBE E<span><span class="calibre5">XTENSION</span></span></span></p>
<hr class="calibre10"/><p class="calibre9">The CUBE extension is also used with the GROUP BY clause to generate aggregates by the listed columns, including the last one. The CUBE extension enables you to get a subtotal for each column listed in the expression, in addition to a grand total for the last column listed. The syntax of the GROUP BY CUBE command sequence is as follows:</p>
<p class="calibre9">SELECT column1 [, column2, ...], aggregate_function(expression)</p>
<p class="calibre9">FROM table1 [, table2, …]</p>
<p class="calibre9">[WHERE condition]</p>
<p class="calibre9">GROUP BY CUBE (column1 [, column2, …])</p>
<p class="calibre9">[HAVING condition]</p>
<p class="calibre9">[ORDER BY column1 [, column2, …]]</p>
<p class="calibre9">For example, <a href="#filepos2332014">Figure 13.22</a> shows the use of the CUBE extension to compute the sales subtotals by month and by product, as well as a grand total.</p>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><span class="calibre14"><a id="filepos2332014"></a><span class="calibre14">FIGURE 13.22 CUBE extension</span></span></span></p><div class="calibre58"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00519.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre73"><span class="calibre8">SOURCE: Course Technology/Cengage Learning</span></p><div class="calibre13"> </div>
<hr class="calibre10"/><p class="calibre9">In <a href="#filepos2332014">Figure 13.22</a>, the CUBE extension also generates subtotals for each combination of month and product. The CUBE extension is particularly useful when you want to compute all possible subtotals within groupings based on multiple dimensions. Cross-tabulations are especially good candidates for application of the CUBE extension.</p>
<p class="calibre69"><span class="calibre8"><a id="filepos2332807"></a>13.8.3 M<span><span class="calibre5">ATERIALIZED</span></span> V<span><span class="calibre5">IEWS</span></span></span></p>
<hr class="calibre10"/><p class="calibre9">The data warehouse normally contains fact tables that store specific measurements of interest to an organization. Such measurements are organized by different dimensions. The vast majority of OLAP business analysis of everyday activity is based on data comparisons that are aggregated at different levels, such as totals by vendor, by product, and by store.</p>
<p class="calibre9">Because businesses normally use a predefined set of summaries for benchmarking, it is reasonable to predefine such summaries for future use by creating summary fact tables. (See <a href="#filepos2265437">Section 13.5.6</a> for a discussion of additional performance-improving techniques.) However, creating multiple summary fact tables that use GROUP BY queries with multiple table joins could become resource-intensive. In addition, data warehouses must be able to maintain up-to-date summarized data at all times. So what happens with the summary fact tables after new sales data have been added to the base fact tables? Under normal circumstances, the summary fact tables are re-created. This operation requires that the SQL code be run again to re-create all summary rows, even when only a few rows need updating. Clearly, this is a time-consuming process.</p>
<p class="calibre9">To save query processing time, most database vendors have implemented additional functions to manage aggregate summaries more efficiently. This new functionality resembles the standard SQL views for which the SQL code is predefined in the database. However, the added difference is that the views also store the preaggregated rows, something like a summary table. For example, Microsoft SQL Server provides indexed views, while Oracle provides materialized views. This section explains the use of materialized views.</p>
<p class="calibre9">A <a id="filepos2334934"></a><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2820991">materialized view</a> is a dynamic table that not only contains the SQL query command to generate the rows, it stores the actual rows. The materialized view is created the first time the query is run, and the summary rows are stored in the table. The materialized view rows are automatically updated when the base tables are updated. That way, the data warehouse administrator will create the view but will not have to worry about updating the view. The use of materialized views is totally transparent to the end user. The OLAP end user can create OLAP queries using the standard fact tables, and the DBMS query optimization feature will automatically use the materialized views if they provide better performance.</p>
<p class="calibre9">The basic syntax for the materialized view is:</p>
<p class="calibre9">CREATE MATERIALIZED VIEW view_name</p>
<p class="calibre9">BUILD {IMMEDIATE | DEFERRED}</p>
<p class="calibre9">REFRESH {[FAST | COMPLETE | FORCE]} ON COMMIT</p>
<p class="calibre9">[ENABLE QUERY REWRITE]</p>
<p class="calibre9">AS select_query;</p>
<p class="calibre9">The BUILD clause indicates when the materialized view rows are actually populated. IMMEDIATE indicates that the materialized view rows are populated right after the command is entered. DEFERRED indicates that the materialized view rows will be populated later. Until then, the materialized view is in an unusable state. The DBMS provides a special routine that an administrator runs to populate materialized views.</p>
<p class="calibre9">The REFRESH clause lets you indicate when and how to update the materialized view when new rows are added to the base tables. FAST indicates that whenever a change is made in the base tables, the materialized view updates only the affected rows. COMPLETE indicates that a complete update will be made for all rows in the materialized view when you rerun the SELECT query on which the view is based. FORCE indicates that the DBMS will first try to do a FAST update; otherwise, it will do a COMPLETE update. The ON COMMIT clause indicates that the updates to the materialized view will take place as part of the commit process of the underlying DML statement—that is, as part of the commitment of the DML transaction that updated the base tables. The ENABLE QUERY REWRITE option allows the DBMS to use the materialized views in query optimization.</p>
<p class="calibre9">To create materialized views, you must have specified privileges and you must complete specified prerequisite steps. As always, you must consult the DBMS documentation for the latest updates. In the case of Oracle, you must create materialized view logs on the base tables of the materialized view. <a href="#filepos2338269">Figure 13.23</a> shows the steps required to create the SALES_MONTH_MV materialized view in the Oracle RDBMS.</p>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><span class="calibre14"><a id="filepos2338269"></a><span class="calibre14">FIGURE 13.23 Creating a materialized view</span></span></span></p><div class="calibre58"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00520.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre73"><span class="calibre8">SOURCE: Course Technology/Cengage Learning</span></p><div class="calibre13"> </div>
<hr class="calibre10"/><p class="calibre9">The materialized view in <a href="#filepos2338269">Figure 13.23</a> computes the monthly total units sold and the total sales aggregated by product. The SALES_MONTH_MV materialized view is configured to automatically update after each change in the base tables. The last row of SALES_MONTH_MV indicates that during October, three units of product ‘WR3/TT3’ were sold for a total of $359.85. <a href="#filepos2339218">Figure 13.24</a> shows the effects of updating the DWDAYSALESFACT base table.</p>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><span class="calibre14"><a id="filepos2339218"></a><span class="calibre14">FIGURE 13.24 Refreshing a materialized view</span></span></span></p><div class="calibre58"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00521.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre73"><span class="calibre8">SOURCE: Course Technology/Cengage Learning</span></p><div class="calibre13"> </div>
<hr class="calibre10"/><p class="calibre9"><a href="#filepos2339218">Figure 13.24</a> shows how the materialized view was automatically updated after the insertion of a new row in the DWDAYSALESFACT table. The last row of SALES_MONTH_MV now shows that in October, four units of product ‘WR3/TT3’ were sold for a total of $466.84.</p>
<p class="calibre9">Although all of the examples in this section focus on SQL extensions to support OLAP reporting in an Oracle DBMS, you have seen just a small fraction of the many business intelligence features currently provided by most DBMS vendors. For example, most vendors provide rich graphical user interfaces to manipulate, analyze, and present the data in multiple formats. <a href="#filepos2340516">Figure 13.25</a> shows two sample screens, one for Oracle and one for Microsoft OLAP products.</p>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><span class="calibre14"><a id="filepos2340516"></a><span class="calibre14">FIGURE 13.25 Sample OLAP applications</span></span></span></p><div class="calibre58"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00522.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre73"><span class="calibre8">SOURCE: Course Technology/Cengage Learning</span></p><div class="calibre13"> </div>
<hr class="calibre10"/><p class="calibre33"> </p>
<hr class="calibre10"/><blockquote class="calibre38"><p class="calibre78"><span class="calibre8"><span class="calibre14"><a id="filepos2340996"></a>SUMMARY</span></span></p></blockquote>
<hr class="calibre10"/><p class="calibre79"><span class="calibre5"><img alt="img" src="images/00030.jpg" class="calibre7"/>   Business intelligence (BI) is a term for a comprehensive, cohesive, and integrated set of applications used to capture, collect, integrate, store, and analyze data with the purpose of generating and presenting information to support business decision making.</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5"><img alt="img" src="images/00030.jpg" class="calibre7"/>   Decision support systems (DSSs) refer to an arrangement of computerized tools used to assist managerial decision making within a business. DSSs were the original precursor of current-generation BI systems.</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5"><img alt="img" src="images/00030.jpg" class="calibre7"/>   Operational data are not well suited for decision support. From the end user’s point of view, decision support data differ from operational data in three main areas: time span, granularity, and dimensionality.</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5"><img alt="img" src="images/00030.jpg" class="calibre7"/>   The data warehouse is an integrated, subject-oriented, time-variant, nonvolatile collection of data that provides support for decision making. The data warehouse is usually a read-only database optimized for data analysis and query processing. A data mart is a small, single-subject data warehouse subset that provides decision support to a small group of people.</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5"><img alt="img" src="images/00030.jpg" class="calibre7"/>   The star schema is a data-modeling technique used to map multidimensional decision support data into a relational database for advanced data analysis. The basic star schema has four components: facts, dimensions, attributes, and attribute hierarchies. Facts are numeric measurements or values that represent a specific business aspect or activity. Dimensions are general qualifying categories that provide additional perspectives to facts. Conceptually, the multidimensional data model is best represented by a three-dimensional cube. Attributes can be ordered in well-defined hierarchies, which provide a top-down organization that is used for two main purposes: to permit aggregation and provide drill-down and roll-up data analysis.</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5"><img alt="img" src="images/00030.jpg" class="calibre7"/>   Data analytics is a subset of BI functionality that provides advanced data analysis tools to extract knowledge from business data. Data analytics can be divided into explanatory and predictive analytics. Explanatory analytics focuses on discovering and explaining data characteristics and relationships. Predictive analytics focuses on creating models to predict future outcomes or events based on the existing data.</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5"><img alt="img" src="images/00030.jpg" class="calibre7"/>   Data mining automates the analysis of operational data to find previously unknown data characteristics, relationships, dependencies, and trends. The data-mining process has four phases: data preparation, data analysis and classification, knowledge acquisition, and prognosis.</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5"><img alt="img" src="images/00030.jpg" class="calibre7"/>   Predictive analytics uses the information generated in the data-mining phase to create advanced predictive models with high degrees of accuracy.</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5"><img alt="img" src="images/00030.jpg" class="calibre7"/>   Online analytical processing (OLAP) refers to an advanced data analysis environment that supports decision making, business modeling, and operations research.</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5"><img alt="img" src="images/00030.jpg" class="calibre7"/>   SQL has been enhanced with extensions that support OLAP-type processing and data generation.</span></p><div class="calibre3"> </div>
<p class="calibre33"> </p>
<hr class="calibre10"/><p class="calibre80"><span class="calibre8"><span class="calibre14"><a id="filepos2345338"></a>KEY TERMS</span></span></p>
<hr class="calibre10"/><blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2281944">algorithms</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2255335">attribute hierarchy</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2180106">business intelligence (BI)</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2319069">cube cache</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5">dashboard</span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2276362">data analytics</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2317938">data cube</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2238663">data mart</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2278949">data mining</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2231697">data warehouse</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2199944">decision support system (DSS)</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2248475">dimension tables</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2247769">dimensions</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2211969">drill down</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2277093">explanatory analytics</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5">extraction, transformation, and loading (ETL)</span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2247029">fact table</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2246689">facts</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2189660">governance</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2190483">key performance indicators (KPIs)</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2188972">master data management (MDM)</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2334934">materialized view</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2247398">metrics</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2317092">multidimensional database management system (MDBMS)</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2316974">multidimensional online analytical processing (MOLAP)</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2292463">online analytical processing (OLAP)</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2273250">partitioning</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2274075">periodicity</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_038.html#filepos2842237">portal</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2277545">predictive analytics</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2306287">relational online analytical processing (ROLAP)</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2273425">replication</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2212147">roll up</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2252372">slice and dice</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2267365">snowflake schema</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2320142">sparsity</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2245927">star schema</a></span></p></blockquote>
<blockquote class="calibre38"><p class="calibre78"><span class="calibre5"><a href="#filepos2230525">very large databases (VLDBs)</a></span></p></blockquote>
<hr class="calibre10"/><p class="calibre63"><span class="calibre35"><img alt="img" src="images/00023.jpg" class="calibre7"/> O<span><span class="calibre68">NLINE</span></span> C<span><span class="calibre68">ONTENT</span></span></span></p>
<p class="calibre9">Flashcards and crossword puzzles for key term practice are available at <a href="http://www.cengagebrain.com"><span class="italic">www.cengagebrain.com</span></a>.</p>
<hr class="calibre10"/><p class="calibre33"> </p>
<hr class="calibre10"/><p class="calibre80"><span class="calibre8"><span class="calibre14"><a id="filepos2351881"></a>REVIEW QUESTIONS</span></span></p>
<hr class="calibre10"/><p class="calibre79"><span class="calibre5">  1.  What is business intelligence? Give some recent examples of BI usage, using the Internet for assistance. What BI benefits have companies found?</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">  2.  Describe the BI framework. Illustrate the evolution of BI.</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">  3.  What are decision support systems, and what role do they play in the business environment?</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">  4.  Explain how the main components of the BI architecture interact to form a system. Describe the evolution of BI information dissemination formats.</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">  5.  What are the most relevant differences between operational data and decision support data?</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">  6.  What is a data warehouse, and what are its main characteristics? How does it differ from a data mart?</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">  7.  Give three examples of likely problems when operational data are integrated into the data warehouse.</span></p><div class="calibre3"> </div>
<p class="calibre9">Use the following scenario to answer Questions 8-14.</p>
<p class="calibre9">While working as a database analyst for a national sales organization, you are asked to be part of its data warehouse project team.</p>
<p class="calibre79"><span class="calibre5">  8.  Prepare a high-level summary of the main requirements for evaluating DBMS products for data warehousing.</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">  9.  Your data warehousing project group is debating whether to create a prototype of a data warehouse before its implementation. The project group members are especially concerned about the need to acquire some data warehousing skills before implementing the enterprise-wide data warehouse. What would you recommend? Explain your recommendations.</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">10.  Suppose that you are selling the data warehouse idea to your users. How would you define multidimensional data analysis for them? How would you explain its advantages to them?</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">11.  The data warehousing project group has invited you to provide an OLAP overview. The group’s members are particularly concerned about the OLAP client/server architecture requirements and how OLAP will fit the existing environment. Your job is to explain the main OLAP client/server components and architectures.</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">12.  One of your vendors recommends using an MDBMS. How would you explain this recommendation to your project leader?</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">13.  The project group is ready to make a final decision, choosing between ROLAP and MOLAP. What should be the basis for this decision? Why?</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">14.  The data warehouse project is in the design phase. Explain to your fellow designers how you would use a star schema in the design.</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">15.  Briefly discuss the OLAP architectural styles with and without data marts.</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">16.  What is OLAP, and what are its main characteristics?</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">17.  Explain ROLAP, and list the reasons you would recommend its use in the relational database environment.</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">18.  Explain the use of facts, dimensions, and attributes in the star schema.</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">19.  Explain multidimensional cubes, and describe how the slice-and-dice technique fits into this model.</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">20.  In the star schema context, what are attribute hierarchies and aggregation levels, and what is their purpose?</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">21.  Discuss the most common performance improvement techniques used in star schemas.</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">22.  What is data analytics? Briefly explain explanatory and predictive analytics.</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">23.  Describe and contrast the focus of data mining and predictive analytics. Give some examples.</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">24.  How does data mining work? Discuss the different phases in the data-mining process.</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">25.  Describe the characteristics of predictive analytics. What is the impact of Big Data (social media) in predictive analytics?</span></p><div class="calibre3"> </div>
<hr class="calibre10"/><p class="calibre63"><span class="calibre35"><img alt="img" src="images/00023.jpg" class="calibre7"/> O<span><span class="calibre68">NLINE</span></span> C<span><span class="calibre68">ONTENT</span></span></span></p>
<p class="calibre9">The databases used for the following problems are available at <a href="http://www.cengagebrain.com"><span class="italic">www.cengagebrain.com</span></a>. These databases are stored in Microsoft Access 2000 format. The databases named <span class="calibre14">Ch13_P1.mdb</span>, <span class="calibre14">Ch13_P3.mdb</span>, and <span class="calibre14">Ch13_P4.mdb</span> contain the data for <a href="#filepos2358919">Problems 1</a>, <a href="#filepos2365545">3</a>, and <a href="#filepos2367527">4</a>, respectively. The data for <a href="#filepos2362318">Problem 2</a> are stored in Microsoft Excel 2000 format at <a href="http://www..cengagebrain.com"><span class="italic">www.cengagebrain.com</span></a>. The spreadsheet filename is <span class="calibre14">Ch13_P2.xls</span>.</p>
<hr class="calibre10"/><p class="calibre48"> </p>
<p class="calibre33"> </p>
<hr class="calibre10"/><p class="calibre80"><span class="calibre8"><span class="calibre14"><a id="filepos2358799"></a>PROBLEMS</span></span></p>
<hr class="calibre10"/><p class="calibre81"><span class="calibre5">  <a id="filepos2358919"></a>1.  The university computer lab’s director keeps track of lab usage, as measured by the number of students using the lab. This function is important for budgeting purposes. The computer lab director assigns you the task of developing a data warehouse to keep track of the lab usage statistics. The main requirements for this database are to:</span></p><div class="calibre3"> </div>
<blockquote class="calibre29"><p class="calibre74">•    Show the total number of users by different time periods.</p></blockquote><div class="calibre3"> </div>
<blockquote class="calibre29"><p class="calibre74">•    Show usage numbers by time period, by major, and by student classification.</p></blockquote><div class="calibre3"> </div>
<blockquote class="calibre29"><p class="calibre74">•    Compare usage for different majors and different semesters.</p></blockquote><div class="calibre3"> </div>
<blockquote class="calibre38"><p class="calibre82"><span class="calibre5">Use the Ch13_P1.mdb database, which includes the following tables:</span></p></blockquote><div class="calibre3"> </div>
<blockquote class="calibre29"><p class="calibre74">•    USELOG contains the student lab access data.</p></blockquote><div class="calibre3"> </div>
<blockquote class="calibre29"><p class="calibre74">•    STUDENT is a dimension table that contains student data.</p></blockquote><div class="calibre3"> </div>
<blockquote class="calibre38"><p class="calibre82"><span class="calibre5">Given the three preceding requirements, and using the Ch13_P1.mdb data, complete the following problems:</span></p></blockquote><div class="calibre3"> </div>
<blockquote class="calibre38"><p class="calibre82"><span class="calibre5"><a></a>a.   Define the main facts to be analyzed. <span class="italic">(Hint:</span> These facts become the source for the design of the fact table.)</span></p></blockquote><div class="calibre3"> </div>
<blockquote class="calibre38"><p class="calibre82"><span class="calibre5"><a id="filepos2360855"></a>b.   Define and describe the appropriate dimensions. <span class="italic">(Hint:</span> These dimensions become the source for the design of the dimension tables.)</span></p></blockquote><div class="calibre3"> </div>
<blockquote class="calibre38"><p class="calibre82"><span class="calibre5"><a id="filepos2361132"></a>c.   Draw the lab usage star schema, using the fact and dimension structures you defined in Problems 1a and 1b.</span></p></blockquote><div class="calibre3"> </div>
<blockquote class="calibre38"><p class="calibre82"><span class="calibre5"><a id="filepos2361378"></a>d.   Define the attributes for each of the dimensions in <a href="#filepos2360855">Problem 1b</a>.</span></p></blockquote><div class="calibre3"> </div>
<blockquote class="calibre38"><p class="calibre82"><span class="calibre5"><a></a>e.   Recommend the appropriate attribute hierarchies.</span></p></blockquote><div class="calibre3"> </div>
<blockquote class="calibre38"><p class="calibre82"><span class="calibre5"><a></a>f.   Implement your data warehouse design, using the star schema you created in <a href="#filepos2361132">Problem 1c</a> and the attributes you defined in <a href="#filepos2361378">Problem 1d</a>.</span></p></blockquote><div class="calibre3"> </div>
<blockquote class="calibre29"><p class="calibre74"><span class="calibre5"><a></a>g.   Create the reports that will meet the requirements listed in this problem’s introduction.</span></p></blockquote>
<p class="calibre79"><span class="calibre5">  <a id="filepos2362318"></a>2.  Victoria Ephanor manages a small product distribution company. Because the business is growing fast, she recognizes that it is time to manage the vast information pool to help guide the accelerating growth. Ephanor, who is familiar with spreadsheet software, currently employs a sales force of four people. She asks you to develop a data warehouse application prototype that will enable her to study sales figures by year, region, salesperson, and product. (This prototype will be used as the basis for a future data warehouse database.)</span></p><div class="calibre3"> </div>
<blockquote class="calibre38"><p class="calibre82"><span class="calibre5">Using the data supplied in the Ch13_P2.xls file, complete the following seven problems:</span></p></blockquote><div class="calibre3"> </div>
<blockquote class="calibre38"><p class="calibre82"><span class="calibre5"><a></a>a.   Identify the appropriate fact table components.</span></p></blockquote><div class="calibre3"> </div>
<blockquote class="calibre38"><p class="calibre82"><span class="calibre5"><a></a>b.   Identify the appropriate dimension tables.</span></p></blockquote><div class="calibre3"> </div>
<blockquote class="calibre38"><p class="calibre82"><span class="calibre5"><a></a>c.   Draw a star schema diagram for this data warehouse.</span></p></blockquote><div class="calibre3"> </div>
<blockquote class="calibre38"><p class="calibre82"><span class="calibre5"><a></a>d.   Identify the attributes for the dimension tables that will be required to solve this problem.</span></p></blockquote><div class="calibre3"> </div>
<blockquote class="calibre38"><p class="calibre82"><span class="calibre5"><a id="filepos2363989"></a>e.   Using Microsoft Excel or any other spreadsheet program that can produce pivot tables, generate a pivot table to show the sales by product and by region. The end user must be able to specify the display of sales for any given year. The sample output is shown in the first pivot table in <a href="#filepos2364427">Figure P13.2E</a>.</span></p></blockquote><div class="calibre3"> </div>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><span class="calibre14"><a id="filepos2364427"></a><span class="calibre14">FIGURE P13.2E Using a pivot table</span></span></span></p><div class="calibre58"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00523.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre73"><span class="calibre8">SOURCE: Course Technology/Cengage Learning</span></p><div class="calibre13"> </div>
<hr class="calibre10"/><blockquote class="calibre38"><p class="calibre82"><span class="calibre5"><a></a>f.   Using <a href="#filepos2363989">Problem 2e</a> as your base, add a second pivot table (see <a href="#filepos2364427">Figure P13.2E</a>) to show the sales by salesperson and by region. The end user must be able to specify sales for a given year or for all years, and for a given product or for all products.</span></p></blockquote><div class="calibre3"> </div>
<blockquote class="calibre38"><p class="calibre82"><span class="calibre5"><a></a>g.   Create a 3D bar graph to show sales by salesperson, by product, and by region. (See the sample output in <a href="#filepos2367084">Figure P13.2G</a>.)</span></p></blockquote><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">  <a id="filepos2365545"></a>3.  David Suker, the inventory manager for a marketing research company, wants to study the use of supplies within the different company departments. Suker has heard that his friend, Victoria Ephanor, has developed a spreadsheet-based data warehouse model that she uses to analyze sales data (see <a href="#filepos2362318">Problem 2</a>). Suker is interested in developing a data warehouse model like Ephanor’s so he can analyze orders by department and by product. He will use Microsoft Access as the data warehouse DBMS and Microsoft Excel as the analysis tool.</span></p><div class="calibre3"> </div>
<blockquote class="calibre38"><p class="calibre82"><span class="calibre5"><a></a>a.   Develop the order star schema.</span></p></blockquote><div class="calibre3"> </div>
<blockquote class="calibre38"><p class="calibre82"><span class="calibre5"><a></a>b.   Identify the appropriate dimension attributes.</span></p></blockquote><div class="calibre3"> </div>
<blockquote class="calibre38"><p class="calibre82"><span class="calibre5"><a></a>c.   Identify the attribute hierarchies required to support the model.</span></p></blockquote><div class="calibre3"> </div>
<blockquote class="calibre38"><p class="calibre82"><span class="calibre5"><a></a>d.   Develop a crosstab report in Microsoft Access, using a 3D bar graph to show orders by product and by department. (The sample output is shown in <a href="#filepos2370054">Figure P13.3</a>.)</span></p></blockquote><div class="calibre3"> </div>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><span class="calibre14"><a id="filepos2367084"></a><span class="calibre14">FIGURE P13.2G 3D bar graph showing the relationships among agent, product, and region</span></span></span></p><div class="calibre58"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00524.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre73"><span class="calibre8">SOURCE: Course Technology/Cengage Learning</span></p><div class="calibre13"> </div>
<hr class="calibre10"/><p class="calibre79"><span class="calibre5">  <a id="filepos2367527"></a>4.  ROBCOR, whose sample data are contained in the database named Ch13_P4.mdb, provides “on-demand” aviation charters using a mix of different aircraft and aircraft types. Because ROBCOR has grown rapidly, its owner has hired you as its first database manager. The company’s database, developed by an outside consulting team, is already in place to help manage all company operations. Your first critical assignment is to develop a decision support system to analyze the charter data. (Review the company’s operations in <a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_015.html#filepos558089">Problems 24</a>-<a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_015.html#filepos561507">31</a> of <a href="CR%215A4MGEVRHD03Z2219SKHVZ3J0KMH_split_015.html#filepos411471">Chapter 3</a>, The Relational Database Model.) The charter operations manager wants to be able to analyze charter data such as cost, hours flown, fuel used, and revenue. She also wants to be able to drill down by pilot, type of airplane, and time periods.</span></p><div class="calibre3"> </div>
<blockquote class="calibre38"><p class="calibre82"><span class="calibre5">Given those requirements, complete the following:</span></p></blockquote><div class="calibre3"> </div>
<blockquote class="calibre38"><p class="calibre82"><span class="calibre5"><a></a>a.   Create a star schema for the charter data.</span></p></blockquote><div class="calibre3"> </div>
<blockquote class="calibre38"><p class="calibre82"><span class="calibre5"><a></a>b.   Define the dimensions and attributes for the charter operation’s star schema.</span></p></blockquote><div class="calibre3"> </div>
<blockquote class="calibre38"><p class="calibre82"><span class="calibre5"><a></a>c.   Define the necessary attribute hierarchies.</span></p></blockquote><div class="calibre3"> </div>
<blockquote class="calibre38"><p class="calibre82"><span class="calibre5"><a></a>d.   Implement the data warehouse design using the design components you developed in Problems 4a-4c.</span></p></blockquote><div class="calibre3"> </div>
<blockquote class="calibre29"><p class="calibre74"><span class="calibre5"><a></a>e.   Generate the reports to illustrate that your data warehouse meets the specified information requirements.</span></p></blockquote>
<blockquote class="calibre29"><p class="calibre74">Using the data provided in the SaleCo snowflake schema in <a href="#filepos2326001">Figure 13.20</a>, solve the following problems. (<span class="italic">Hint</span>: In <a href="#filepos2371102">Problems 5</a>–<a href="#filepos2372657">11</a>, use the ROLLUP command.)</p></blockquote><div class="calibre3"> </div>
<hr class="calibre10"/><p class="calibre69"><span class="calibre8"><span class="calibre14"><a id="filepos2370054"></a><span class="calibre14">FIGURE P13.3 Crosstab report: orders by product and department</span></span></span></p><div class="calibre58"> </div>
<hr class="calibre10"/><p class="calibre11"><img alt="img" src="images/00525.jpg" class="calibre7"/></p><div class="calibre32"> </div>
<p class="calibre73"><span class="calibre8">SOURCE: Course Technology/Cengage Learning</span></p><div class="calibre13"> </div>
<hr class="calibre10"/><hr class="calibre10"/><p class="calibre63"><span class="calibre35"><img alt="img" src="images/00023.jpg" class="calibre7"/> O<span><span class="calibre68">NLINE</span></span> C<span><span class="calibre68">ONTENT</span></span></span></p>
<p class="calibre9">The script files used to populate the SaleCo database are available at <a href="http://www.cengagebrain.com"><span class="italic">www.cengagebrain.com</span></a>. The script files assume the use of an Oracle RDBMS. If you use a different DBMS, consult the documentation to verify whether the vendor supports similar functionality and what the proper syntax is for your DBMS.</p>
<hr class="calibre10"/><p class="calibre79"><span class="calibre5">  <a id="filepos2371102"></a>5.  What is the SQL command to list the total sales by customer and by product, with subtotals by customer and a grand total for all product sales?</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">  <a></a>6.  What is the SQL command to list the total sales by customer, month, and product, with subtotals by customer and by month and a grand total for all product sales?</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">  <a></a>7.  What is the SQL command to list the total sales by region and customer, with subtotals by region and a grand total for all sales?</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">  <a></a>8.  What is the SQL command to list the total sales by month and product category, with subtotals by month and a grand total for all sales?</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5">  <a></a>9.  What is the SQL command to list the number of product sales (number of rows) and total sales by month, with subtotals by month and a grand total for all sales?</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5"><a id="filepos2372352"></a>10.  What is the SQL command to list the number of product sales (number of rows) and total sales by month and product category, with subtotals by month and product category and a grand total for all sales?</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5"><a id="filepos2372657"></a>11.  What is the SQL command to list the number of product sales (number of rows) and total sales by month, product category, and product, with subtotals by month and product category and a grand total for all sales?</span></p><div class="calibre3"> </div>
<p class="calibre79"><span class="calibre5"><a></a>12.  Using the answer to <a href="#filepos2372352">Problem 10</a> as your base, what command would you need to generate the same output but with subtotals in all columns? (<span class="italic">Hint</span>: Use the CUBE command.)</span></p><div class="calibre3"> </div>
<div class="calibre67"> </div><hr class="calibre10"/><blockquote class="calibre38"><p class="calibre63"><span class="calibre8"><a id="filepos2373333"></a><sup class="calibre24">1</sup> In 1989, while working at Gartner Inc., Howard Dresner popularized BI as an umbrella term to describe a set of concepts and methods to improve business decision making by using fact-based support systems (<span class="italic"><a href="http://www.computerworld.com/action/article">www.computerworld.com/action/article</a>.do?command= viewArticleBasic&amp; articleId=266298</span>).</span></p></blockquote>
<blockquote class="calibre38"><p class="calibre63"><span class="calibre8"><a id="filepos2373820"></a><sup class="calibre24">2</sup> Inmon, Bill and Chuck Kelley, “The Twelve Rules of Data Warehouse for a Client/Server World,” <span class="italic">Data Management Review</span>, 4(5), May 1994.</span></p></blockquote>
<blockquote class="calibre38"><p class="calibre63"><span class="calibre8"><a id="filepos2374092"></a><sup class="calibre24">3</sup> Inmon, Bill and Chuck Kelley, “The Twelve Rules of Data Warehouse for a Client/Server World,” <span class="italic">Data Management Review</span>, 4(5), May 1994.</span></p></blockquote>
<blockquote class="calibre38"><p class="calibre63"><span class="calibre8"><a id="filepos2374364"></a><sup class="calibre24">4</sup> “BI Home Runs: 15 Organizations making better business decisions through BI technology,” Ellen Fanning, <span class="italic">Computerworld</span>, September 18, 2006.</span></p></blockquote>  <div class="mbppagebreak" id="calibre_pb_30"></div></body></html>
